{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ESN_topology_translate_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/brain/research/babelfish/colab:colab_notebook",
        "kind": "shared"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWrcgjEblcG8",
        "colab_type": "text"
      },
      "source": [
        "##Analysis of NN based activation functions: y=g(x)\n",
        "\n",
        "### Preparation\n",
        "Start your own Colab runtime with this command:\n",
        "\n",
        "```\n",
        "rabbit --verifiable build -c opt \\\n",
        "  --define=babelfish_task=mt \\\n",
        "  //learning/brain/research/babelfish/colab:colab_notebook.par\n",
        "\n",
        "borgcfg learning/brain/research/babelfish/colab/colab.borg \\\n",
        "  --vars=\"task=mt,cell=vz,charged_user=translate-train\" \\\n",
        "  --skip_confirmation reload\n",
        "```\n",
        "Then connect your colab against this runtime\n",
        "(it will be called 'BabelFish Colab USERNAME (mt)')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBZbNwtVP6Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model from the checkpoint \n",
        "ml_dash_name = 'esn_actNN_gx_rnnL2_norm1_run08'\n",
        "checkpoint = '/cns/vz-d/home/harshx/brain/rs=6.3/'+ ml_dash_name +'/train/' + 'ckpt-00020600' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1iuU4nNukFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVIOVGNjGh_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-WmJhJ0GioW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVAXimm9cDlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b6Zwuk-cDjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWNmZmz_cDgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hltl62rCcDdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0V1Da2PcDa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIvup82acDWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpggo0-XcDTb",
        "colab_type": "code",
        "colab": {
          "height": 1000
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275192367,
          "user_tz": 240,
          "elapsed": 115238,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "1ffa18ff-5246-419e-a33b-851d1974cfd4"
      },
      "source": [
        "from google3.pyglib import build_data, resources\n",
        "print(build_data.BuildData())\n",
        "\n",
        "from colabtools import adhoc_import\n",
        "with adhoc_import.Google3SubmittedChangelist(\n",
        "    behavior='preferred',\n",
        "    build_targets=['//third_party/py/networkx:utils_tests_test_misc.python3']):\n",
        "  adhoc_import.Reload(resources)\n",
        "  import networkx as nx\n",
        "\n",
        "help(nx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built on Thu May 21 21:57:21 2020 (1590123441)\n",
            "Built by harshx@odqb3.prod.google.com:/google/src/cloud/harshx/82/.snapshot/391/google3\n",
            "Built as //learning/brain/research/babelfish/colab:colab_notebook\n",
            "Build ID: 1dc474dc-49c8-4b3b-84a2-97b7c37dacad\n",
            "Built from changelist 312358057 in a modified client based on //depot/google3 in CitC workspace build-secure-info:source-uri at snapshot 391\n",
            "Build platform: gcc-4.X.Y-crosstool-v18-llvm-grtev4-k8\n",
            "Build tool: Blaze, release blaze-2020.05.10-1 (mainline @310756764)\n",
            "Built with par options [--compress]\n",
            "Currently running under Python 3.6.7: embedded.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Help on package networkx:\n",
            "\n",
            "NAME\n",
            "    networkx\n",
            "\n",
            "DESCRIPTION\n",
            "    NetworkX\n",
            "    ========\n",
            "    \n",
            "    NetworkX is a Python package for the creation, manipulation,\n",
            "    and study of the structure, dynamics, and functions\n",
            "    of complex networks.\n",
            "    \n",
            "    Website (including documentation)::\n",
            "    \n",
            "        http://networkx.github.io\n",
            "    \n",
            "    Mailing list::\n",
            "    \n",
            "        https://groups.google.com/forum/#!forum/networkx-discuss\n",
            "    \n",
            "    Source::\n",
            "    \n",
            "        https://github.com/networkx/networkx\n",
            "    \n",
            "    Bug reports::\n",
            "    \n",
            "        https://github.com/networkx/networkx/issues\n",
            "    \n",
            "    Simple example\n",
            "    --------------\n",
            "    \n",
            "    Find the shortest path between two nodes in an undirected graph::\n",
            "    \n",
            "        >>> import networkx as nx\n",
            "        >>> G = nx.Graph()\n",
            "        >>> G.add_edge('A', 'B', weight=4)\n",
            "        >>> G.add_edge('B', 'D', weight=2)\n",
            "        >>> G.add_edge('A', 'C', weight=3)\n",
            "        >>> G.add_edge('C', 'D', weight=4)\n",
            "        >>> nx.shortest_path(G, 'A', 'D', weight='weight')\n",
            "        ['A', 'B', 'D']\n",
            "    \n",
            "    Bugs\n",
            "    ----\n",
            "    \n",
            "    Please report any bugs that you find `here <https://github.com/networkx/networkx/issues>`_.\n",
            "    Or, even better, fork the repository on GitHub and create a pull request (PR).\n",
            "    \n",
            "    License\n",
            "    -------\n",
            "    \n",
            "    Released under the 3-Clause BSD license::\n",
            "    \n",
            "       Copyright (C) 2004-2018 NetworkX Developers\n",
            "       Aric Hagberg <hagberg@lanl.gov>\n",
            "       Dan Schult <dschult@colgate.edu>\n",
            "       Pieter Swart <swart@lanl.gov>\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "\n",
            "\n",
            "SUBMODULES\n",
            "    adjacency\n",
            "    adjlist\n",
            "    algebraicconnectivity\n",
            "    algorithms\n",
            "    all\n",
            "    assortativity\n",
            "    astar\n",
            "    atlas\n",
            "    attracting\n",
            "    attrmatrix\n",
            "    beamsearch\n",
            "    betweenness\n",
            "    betweenness_subset\n",
            "    biconnected\n",
            "    binary\n",
            "    bipartite\n",
            "    boundary\n",
            "    breadth_first_search\n",
            "    centrality\n",
            "    chains\n",
            "    chordal\n",
            "    classes\n",
            "    classic\n",
            "    clique\n",
            "    closeness\n",
            "    cluster\n",
            "    coloring\n",
            "    communicability_alg\n",
            "    community\n",
            "    components\n",
            "    connected\n",
            "    connectivity\n",
            "    convert\n",
            "    convert_matrix\n",
            "    core\n",
            "    coreviews\n",
            "    correlation\n",
            "    covering\n",
            "    current_flow_betweenness\n",
            "    current_flow_betweenness_subset\n",
            "    current_flow_closeness\n",
            "    cuts\n",
            "    cycles\n",
            "    cytoscape\n",
            "    dag\n",
            "    degree_alg\n",
            "    degree_seq\n",
            "    dense\n",
            "    depth_first_search\n",
            "    digraph\n",
            "    directed\n",
            "    distance_measures\n",
            "    distance_regular\n",
            "    dominance\n",
            "    dominating\n",
            "    drawing\n",
            "    duplication\n",
            "    edgedfs\n",
            "    edgelist\n",
            "    ego\n",
            "    eigenvector\n",
            "    euler\n",
            "    exception\n",
            "    expanders\n",
            "    filters\n",
            "    flow\n",
            "    flow_matrix\n",
            "    function\n",
            "    generators\n",
            "    generic\n",
            "    geometric\n",
            "    gexf\n",
            "    gml\n",
            "    gpickle\n",
            "    graph\n",
            "    graph6\n",
            "    graphical\n",
            "    graphmatrix\n",
            "    graphml\n",
            "    graphviews\n",
            "    harmonic\n",
            "    hierarchy\n",
            "    hits_alg\n",
            "    hybrid\n",
            "    isolate\n",
            "    isomorphism\n",
            "    jit\n",
            "    joint_degree_seq\n",
            "    json_graph\n",
            "    katz\n",
            "    laplacianmatrix\n",
            "    lattice\n",
            "    layout\n",
            "    leda\n",
            "    linalg\n",
            "    line\n",
            "    link_analysis\n",
            "    link_prediction\n",
            "    load\n",
            "    lowest_common_ancestors\n",
            "    matching\n",
            "    minors\n",
            "    mis\n",
            "    mixing\n",
            "    modularitymatrix\n",
            "    multidigraph\n",
            "    multigraph\n",
            "    multiline_adjlist\n",
            "    mycielski\n",
            "    neighbor_degree\n",
            "    node_link\n",
            "    nx_agraph\n",
            "    nx_pydot\n",
            "    nx_pylab\n",
            "    nx_shp\n",
            "    nx_yaml\n",
            "    operators\n",
            "    ordered\n",
            "    pagerank_alg\n",
            "    pairs\n",
            "    pajek\n",
            "    product\n",
            "    random_clustered\n",
            "    random_graphs\n",
            "    reaching\n",
            "    readwrite\n",
            "    relabel\n",
            "    release\n",
            "    reportviews\n",
            "    richclub\n",
            "    semiconnected\n",
            "    shortest_paths\n",
            "    similarity\n",
            "    simple_paths\n",
            "    small\n",
            "    smetric\n",
            "    social\n",
            "    sparse6\n",
            "    spectrum\n",
            "    stochastic\n",
            "    strongly_connected\n",
            "    structuralholes\n",
            "    subgraph_alg\n",
            "    swap\n",
            "    tests\n",
            "    tournament\n",
            "    traversal\n",
            "    tree\n",
            "    trees\n",
            "    triads\n",
            "    unary\n",
            "    unweighted\n",
            "    utils\n",
            "    vitality\n",
            "    voronoi\n",
            "    weakly_connected\n",
            "    weighted\n",
            "    wiener\n",
            "\n",
            "DATA\n",
            "    __bibtex__ = '@inproceedings{hagberg-2008-exploring,\\nauthor = ...\\nad...\n",
            "    __license__ = 'BSD'\n",
            "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
            "\n",
            "VERSION\n",
            "    2.1\n",
            "\n",
            "DATE\n",
            "    Mon Jul 20 19:59:48 2020\n",
            "\n",
            "AUTHOR\n",
            "    Aric Hagberg <hagberg@lanl.gov>\n",
            "    Dan Schult <dschult@colgate.edu>\n",
            "    Pieter Swart <swart@lanl.gov>\n",
            "\n",
            "FILE\n",
            "    /export/hda3/borglet/remote_hdd_fs_dirs/0.harshx_babelfish_colab_mt.kernel.translate-train.490764461609.14b334fb3717c109/mount/logs.0.harshx_babelfish_colab_mt.kernel.translate-train.490764461609/tmp/colab-adhoc_import-tmp-240242-231851a191bb5e/colab-root/google3/third_party/py/networkx/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT_GBcrHGnKY",
        "colab_type": "text"
      },
      "source": [
        "#Checking the weight topology code\n",
        "1. SCR = lower subdiag + upper right corner\n",
        "2. Chain\n",
        "3. Permutation\n",
        "4. Ring\n",
        "5. Random\n",
        "\n",
        "Note: this is the mask which will be multiplied to the inititialized matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNNuPzt_GjRf",
        "colab_type": "code",
        "colab": {
          "height": 36
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275199968,
          "user_tz": 240,
          "elapsed": 7474,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "fe8ec8b2-2492-41a8-99c3-12a87d8c36fa"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import sys, math\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZK-OPuJKLZN",
        "colab_type": "code",
        "colab": {
          "height": 34
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590131265513,
          "user_tz": 240,
          "elapsed": 380,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "8dd7833f-8d09-4dc4-dea5-d5384cd65f4b"
      },
      "source": [
        "w_random = tf.random.uniform([3, 3])\n",
        "tensor = tf.range(10)\n",
        "tf.print(w_random)\n",
        "tf.print(tensor, output_stream=sys.stderr)\n",
        "# print(w_random)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'PrintV2_14' type=PrintV2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Lu9Yk3KRGq",
        "colab_type": "code",
        "colab": {
          "height": 70
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590131554591,
          "user_tz": 240,
          "elapsed": 392,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "cf88f362-7875-478b-8e52-9df39a5da77e"
      },
      "source": [
        "  sess = tf.compat.v1.Session()  \n",
        "  with sess.as_default():  \n",
        "      w_random = tf.random.uniform([3, 3]) \n",
        "      print_op = tf.print(\"tensors:\", w_random,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      # with tf.control_dependencies([print_op]):  \n",
        "      #  tripled_tensor = tensor * 3  \n",
        "      sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: [[0.0363430977 0.568793416 0.900764346]\n",
            " [0.681818485 0.701964736 0.88309145]\n",
            " [0.366456389 0.958831191 0.102034092]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q33K2D8KVVh",
        "colab_type": "code",
        "colab": {
          "height": 34
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590131485952,
          "user_tz": 240,
          "elapsed": 432,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "8b559f3a-b6b3-48f7-e755-f9be5a165673"
      },
      "source": [
        "tensor = tf.range(10)  \n",
        "tf.print(tensor, output_stream=sys.stdout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'PrintV2_18' type=PrintV2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3ESpwvVOBBW",
        "colab_type": "code",
        "colab": {
          "height": 129
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1594154023534,
          "user_tz": 240,
          "elapsed": 357,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "78f4bab0-c98f-4c44-85f4-b683141810ee"
      },
      "source": [
        "# scr_lower (sub-diag)\n",
        "sess2 = tf.compat.v1.Session()  \n",
        "\n",
        "with sess2.as_default(): # initialize the reservoir weights\n",
        "      shape = (5, 5)\n",
        "      diagonal = tf.ones(shape[0])  \n",
        "      w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      w_scr = tf.roll(w_diag, shift=[1, 0], axis=[0, 1]) \n",
        "      print_op = tf.print(\"SCR-lower:\\n\", w_scr,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sess2.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SCR-lower:\n",
            " [[0 0 0 0 1]\n",
            " [1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtX5GxiePs6H",
        "colab_type": "code",
        "colab": {
          "height": 123
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1594154701176,
          "user_tz": 240,
          "elapsed": 318,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "fa094a70-87fa-4602-a859-f9516d960b2d"
      },
      "source": [
        "# scr_upper \n",
        "sessu = tf.compat.v1.Session()  \n",
        "\n",
        "with sessu.as_default(): # initialize the reservoir weights\n",
        "      shape = (5, 5)\n",
        "      diagonal = tf.ones(shape[0])  \n",
        "      w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      w_scr = tf.roll(w_diag, shift=[-1, 0], axis=[0, 1]) \n",
        "      print_op = tf.print(\"SCR-upper:\\n\", w_scr,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessu.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SCR-upper:\n",
            " [[0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb24nwekPsg2",
        "colab_type": "code",
        "colab": {
          "height": 105
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590182428187,
          "user_tz": 240,
          "elapsed": 367,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "f1ff8c87-d4c7-4a9b-8029-4845a614ffec"
      },
      "source": [
        "# scr_both\n",
        "sessb = tf.compat.v1.Session()  \n",
        "\n",
        "with sessb.as_default(): # initialize the reservoir weights\n",
        "      shape = (5, 5)\n",
        "      diagonal = tf.ones(shape[0])  \n",
        "      w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      w_scr = tf.roll(w_diag, shift=[-1, 0], axis=[0, 1]) + tf.roll(w_diag, shift=[1, 0], axis=[0, 1]) \n",
        "      print_op = tf.print(\"tensors:\", w_scr,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessb.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: [[0 1 0 0 1]\n",
            " [1 0 1 0 0]\n",
            " [0 1 0 1 0]\n",
            " [0 0 1 0 1]\n",
            " [1 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWkwPlakQxn9",
        "colab_type": "code",
        "colab": {
          "height": 123
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1594154785552,
          "user_tz": 240,
          "elapsed": 492,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "36dc968a-fdc7-4707-c50a-c2f57faa7d26"
      },
      "source": [
        "# scr_bd (both+diag)\n",
        "sessbd = tf.compat.v1.Session()  \n",
        "\n",
        "with sessbd.as_default(): # initialize the reservoir weights\n",
        "      shape = (5, 5)\n",
        "      diagonal = tf.ones(shape[0])  \n",
        "      w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      w_scr = tf.roll(w_diag, shift=[-1, 0], axis=[0, 1]) + tf.roll(w_diag, shift=[1, 0], axis=[0, 1]) +w_diag\n",
        "      print_op = tf.print(\"SCR-bd:\\n\", w_scr,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessbd.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SCR-bd:\n",
            " [[1 1 0 0 1]\n",
            " [1 1 1 0 0]\n",
            " [0 1 1 1 0]\n",
            " [0 0 1 1 1]\n",
            " [1 0 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veACuwo7nc7A",
        "colab_type": "code",
        "colab": {
          "height": 70
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590272443015,
          "user_tz": 240,
          "elapsed": 539,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "588f0be7-5a49-4a27-ad5d-107789921d17"
      },
      "source": [
        "# for input weight: scrl topology\n",
        "sessil = tf.compat.v1.Session()  \n",
        "\n",
        "with sessil.as_default(): # initialize the reservoir weights\n",
        "      shape = (3, 6)\n",
        "      # shape0, shape1 = shape[-2], shape[-1]\n",
        "      dim0, dim1 = shape[-2], shape[-1]\n",
        "      if dim0 <= dim1:\n",
        "        shape0, shape1 = dim0, dim1\n",
        "        do_transpose = False\n",
        "      else:\n",
        "        shape0, shape1 = dim1, dim0\n",
        "        do_transpose = True\n",
        "      # assuming shape0 < shape1:\n",
        "      repeat = math.ceil(shape1/shape0) - 1\n",
        "      w_scr = tf.eye(shape0)\n",
        "      for i in range(repeat):\n",
        "        if i == repeat - 1: # truncate\n",
        "          w_diag = tf.eye(shape0)\n",
        "          w_scr = tf.concat([w_scr, w_diag[:, :(shape1-shape0)]], axis=1)\n",
        "        else:\n",
        "          w_scr = tf.concat([w_scr, tf.eye(shape0) ], axis=1)\n",
        "      w_scr = tf.roll(w_scr, shift=[-1, 0], axis=[0, 1])\n",
        "      # the transpose condition\n",
        "      if do_transpose:\n",
        "        w_scr = tf.transpose(w_scr, perm=[1, 0])\n",
        "\n",
        "      print_op = tf.print(\"tensors:\", w_scr,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessil.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: [[0 1 0 0 1 0]\n",
            " [0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXlGYc-v2qEm",
        "colab_type": "code",
        "colab": {
          "height": 123
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592554693127,
          "user_tz": 240,
          "elapsed": 586,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "fa2a22aa-ec79-4217-9039-01f72ab9be59"
      },
      "source": [
        "# for input weight: scrbd topology\n",
        "sessibd = tf.compat.v1.Session()  \n",
        "\n",
        "with sessibd.as_default(): # initialize the reservoir weights\n",
        "      shape = (6,6)\n",
        "      # shape0, shape1 = shape[-2], shape[-1]\n",
        "      dim0, dim1 = shape[-2], shape[-1]\n",
        "      if dim0 <= dim1:\n",
        "        shape0, shape1 = dim0, dim1\n",
        "        do_transpose = False\n",
        "      else:\n",
        "        shape0, shape1 = dim1, dim0\n",
        "        do_transpose = True\n",
        "      # assuming shape0 < shape1:\n",
        "      repeat = math.ceil(shape1/shape0) - 1\n",
        "      w_scr = tf.eye(shape0)\n",
        "      for i in range(repeat):\n",
        "        if i == repeat - 1: # truncate\n",
        "          w_diag = tf.eye(shape0)\n",
        "          w_scr = tf.concat([w_scr, w_diag[:, :(shape1-shape0)]], axis=1)\n",
        "        else:\n",
        "          w_scr = tf.concat([w_scr, tf.eye(shape0) ], axis=1)\n",
        "      D_mat = w_scr\n",
        "      adj_mat = tf.roll(w_scr, shift=[-1, 0], axis=[0, 1]) + tf.roll(w_scr, shift=[1, 0], axis=[0, 1])\n",
        "      w_scr = adj_mat + D_mat\n",
        "      # the transpose condition\n",
        "      if do_transpose:\n",
        "        w_scr = tf.transpose(w_scr, perm=[1, 0])\n",
        "\n",
        "      mask = w_scr # tf.cast(w_scr, dtype=dtype)\n",
        "      # should have v and mask\n",
        "      # D_mat = D_mat*tf.reduce_sum(adj_mat, axis=-1)[0]  # scalar\n",
        "      # v = D_mat - adj_mat\n",
        "      print_op = tf.print(\"tensors:\", mask,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessibd.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: [[1 1 0 0 0 1]\n",
            " [1 1 1 0 0 0]\n",
            " [0 1 1 1 0 0]\n",
            " [0 0 1 1 1 0]\n",
            " [0 0 0 1 1 1]\n",
            " [1 0 0 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K53U0oDQX9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rotation matrix which takes care of the average sequence length\n",
        "# scr_lower (sub-diag)\n",
        "sessr = tf.compat.v1.Session()  \n",
        "\n",
        "with sessr.as_default(): # initialize the reservoir weights\n",
        "      shape = (6, 6)\n",
        "      avg_L = 3 # average sequence length\n",
        "      num_rotates = math.ceil(shape[-1]/avg_L) # NOTE: take the smaller shape, as we already repeat for the longer dim.\n",
        "      print(num_rotates)\n",
        "      diagonal = tf.ones(shape[0])  \n",
        "      w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      w_scr_base = tf.roll(w_diag, shift=[1, 0], axis=[0, 1])\n",
        "      mat = []\n",
        "      \n",
        "      for r in range(num_rotates):\n",
        "        temp = tf.roll(w_scr_base, shift=[r*avg_L, 0], axis=[0, 1])\n",
        "        if r==0:\n",
        "          w_scr = temp\n",
        "        else:\n",
        "          w_scr = w_scr + temp\n",
        "        mat.append(temp)\n",
        "      print_op = tf.print(\"tensors:\", w_scr,mat,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessr.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEds6zDtK2SE",
        "colab_type": "code",
        "colab": {
          "height": 148
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275265758,
          "user_tz": 240,
          "elapsed": 351,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "f10ba850-a875-4720-c44e-518278be60c8"
      },
      "source": [
        "# Reservoir rotation matrix : which takes care of the average sequence length\n",
        "\n",
        "sessr = tf.compat.v1.Session()  \n",
        "\n",
        "with sessr.as_default(): # initialize the reservoir weights\n",
        "      shape = (6, 6)\n",
        "      diagonal = tf.ones(shape[0])  \n",
        "      w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      w_scr = tf.roll(w_diag, shift=[1, 0], axis=[0, 1])\n",
        "\n",
        "      avg_L = 3 # average sequence length\n",
        "      num_rotates = math.ceil(shape[-1]/avg_L)\n",
        "      for r in range(num_rotates):\n",
        "        temp = tf.roll(w_scr, shift=[r*avg_L, 0], axis=[0, 1])\n",
        "        if r==0:\n",
        "          w_rot = temp\n",
        "        else:\n",
        "          w_rot = w_rot + temp\n",
        "      print_op = tf.print(\"Rotation:\\n\", w_rot,\n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessr.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rotation:\n",
            " [[0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]\n",
            " [0 1 0 0 1 0]\n",
            " [0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]\n",
            " [0 1 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74OKWCLTK2P_",
        "colab_type": "code",
        "colab": {
          "height": 223
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275296113,
          "user_tz": 240,
          "elapsed": 424,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "ea171d19-30c8-4b2a-e519-c5ee53dde394"
      },
      "source": [
        "# for input weight: rotation topology\n",
        "sessir = tf.compat.v1.Session()  \n",
        "\n",
        "with sessir.as_default(): # initialize the reservoir weights\n",
        "      shape = (6,6)\n",
        "      # shape0, shape1 = shape[-2], shape[-1]\n",
        "      dim0, dim1 = shape[-2], shape[-1]\n",
        "      if dim0 <= dim1: # shape0 is the smaller dim\n",
        "        shape0, shape1 = dim0, dim1\n",
        "        do_transpose = False\n",
        "      else:\n",
        "        shape0, shape1 = dim1, dim0\n",
        "        do_transpose = True\n",
        "      # assuming shape0 < shape1:\n",
        "      repeat = math.ceil(shape1/shape0) - 1\n",
        "      w_scr = tf.eye(shape0)\n",
        "      for i in range(repeat):\n",
        "        if i == repeat - 1: # truncate\n",
        "          w_diag = tf.eye(shape0)\n",
        "          w_scr = tf.concat([w_scr, w_diag[:, :(shape1-shape0)]], axis=1)\n",
        "        else:\n",
        "          w_scr = tf.concat([w_scr, tf.eye(shape0) ], axis=1)\n",
        "      w_scr = tf.roll(w_scr, shift=[1, 0], axis=[0, 1])\n",
        "      # the transpose condition\n",
        "      if do_transpose:\n",
        "        w_scr = tf.transpose(w_scr, perm=[1, 0])\n",
        "      \n",
        "      avg_L = 3 # average sequence length\n",
        "      num_rotates = math.ceil(shape0/avg_L)\n",
        "      for r in range(num_rotates):\n",
        "        temp = tf.roll(w_scr, shift=[r*avg_L, 0], axis=[0, 1])\n",
        "        if r==0:\n",
        "          w_rot = temp\n",
        "        else:\n",
        "          w_rot = w_rot + temp\n",
        "\n",
        "      print_op = tf.print(\"tensors:\", w_rot,  w_rot[:6, :6],\n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessir.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: [[0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]\n",
            " [0 1 0 0 1 0]\n",
            " [0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]\n",
            " [0 1 0 0 1 0]] [[0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]\n",
            " [0 1 0 0 1 0]\n",
            " [0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0]\n",
            " [0 1 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89O4Z643K2NM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQfkalkEK2Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK_rT4zPPpMZ",
        "colab_type": "code",
        "colab": {
          "height": 246
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590281839481,
          "user_tz": 240,
          "elapsed": 387,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "a327211d-ec8d-4531-ab6b-563dfb1024e4"
      },
      "source": [
        "\n",
        "sessa = tf.compat.v1.Session()  \n",
        "\n",
        "with sessa.as_default():\n",
        "      shape = (5, 6)\n",
        "      mat = tf.random.normal(shape)  \n",
        "      #w_diag = tf.linalg.diag(diagonal)#, k = -1)\n",
        "      # w_scr = mat[mat<0] #tf.roll(mat, shift=[1, 0], axis=[0, 1]) \n",
        "      # w_scr = tf.maximum(mat, 0)\n",
        "      #mask_np = tf.make_ndarray(mat)\n",
        "      #print(mask_np)\n",
        "      w_scr_mask = tf.where(mat>0, tf.ones(mat.shape), tf.zeros(mat.shape))\n",
        "      w_scr = mat*w_scr_mask\n",
        "      print_op = tf.print(\"tensors:\", w_scr, 'mat', mat, w_scr_mask,  \n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessa.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: [[-0 -0 0.490858823 -0 0.402715683 -0]\n",
            " [-0 -0 -0 -0 0.704687059 0.204413876]\n",
            " [0.770711303 0.257065117 -0 -0 0.442749828 1.3006258]\n",
            " [0.0617309 -0 -0 1.62153125 -0 0.691740453]\n",
            " [-0 0.0859779418 0.742853224 0.87780422 -0 0.880521715]] mat [[-0.0185288079 -0.483362049 0.490858823 -0.414317876 0.402715683 -0.526476204]\n",
            " [-2.8118341 -2.16614079 -0.303864509 -0.528555155 0.704687059 0.204413876]\n",
            " [0.770711303 0.257065117 -0.0175612476 -0.305617481 0.442749828 1.3006258]\n",
            " [0.0617309 -0.0796477646 -1.0349772 1.62153125 -0.597598433 0.691740453]\n",
            " [-1.23412371 0.0859779418 0.742853224 0.87780422 -0.3288396 0.880521715]] [[0 0 1 0 1 0]\n",
            " [0 0 0 0 1 1]\n",
            " [1 1 0 0 1 1]\n",
            " [1 0 0 1 0 1]\n",
            " [0 1 1 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XDjxDgmuvjB",
        "colab_type": "code",
        "colab": {
          "height": 34
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1590894774189,
          "user_tz": 240,
          "elapsed": 411,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "f29697b3-cab2-4ebe-b5e1-9c136c515f18"
      },
      "source": [
        "# convert list of tensors to tensor\n",
        "# x = tf.constant([1, 4])\n",
        "# y = tf.constant([2, 5])\n",
        "# z = tf.constant([3, 6])\n",
        "# tf.stack([x, y, z])\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  x1 = tf.zeros([7, 5])\n",
        "  y1 = tf.ones([7, 5])\n",
        "\n",
        "  # tf.print(x1)\n",
        "\n",
        "  z1 = tf.concat([tf.reshape(x1, [*x1.shape, 1]), tf.reshape(y1, [*y1.shape,1])], axis=-1)\n",
        "  #cz1 = tf.concat([x1, y1], axis=-1)\n",
        "  print_op = tf.print(\"tensors:\", x1.shape, y1.shape, z1.shape,\n",
        "                          output_stream=sys.stdout)  \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors: TensorShape([Dimension(7), Dimension(5)]) TensorShape([Dimension(7), Dimension(5)]) TensorShape([Dimension(7), Dimension(5), Dimension(2)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKZmvwe_pvTm",
        "colab_type": "code",
        "colab": {
          "height": 194
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1591237379192,
          "user_tz": 240,
          "elapsed": 403,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "32f0cb19-ae5b-4eab-c11f-cd86328d4108"
      },
      "source": [
        "['scrl']*10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl',\n",
              " 'scrl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELCzxkeHEpxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _old_projection_out(input_vec, in_wt_vector, rot_num, in_dim, res_dim):\n",
        "  print('proj out :', input_vec, in_wt_vector, rot_num, input_vec.shape,\n",
        "        in_wt_vector.shape)\n",
        "  print('shape check : ', res_dim, in_dim)\n",
        "  # case I:  res_dim >= in_dim\n",
        "  if res_dim >= in_dim :\n",
        "    # concat inputs to match the res_sim\n",
        "    repeat = math.ceil(res_dim / in_dim) - 1 \n",
        "    print('repeat: ', repeat)\n",
        "    for i in range(repeat):\n",
        "      if i == repeat - 1:\n",
        "        input_vec = tf.concat([input_vec, input_vec[:, :(res_dim-repeat*(in_dim-1)-1)]], \n",
        "                              axis=-1)\n",
        "      else:\n",
        "        input_vec = tf.concat([input_vec, input_vec], axis=-1)\n",
        "    # rotate the input_vec\n",
        "    input_vec = tf.roll(input_vec, shift=[0, rot_num], axis=[-2, -1])\n",
        "    print('final in vec: ', input_vec, in_wt_vector)\n",
        "    proj_vec = in_wt_vector * input_vec\n",
        "  else: # Case II: res_dim < in_dim\n",
        "    repeat = math.ceil(in_dim/res_dim)-1\n",
        "    print('repeat num :', repeat, res_dim, in_dim, input_vec.shape)\n",
        "    # pad zeros\n",
        "    zeros_vec = tf.zeros([input_vec.shape[0], in_dim-repeat*(res_dim-1)-1])\n",
        "    print('zeros: ', zeros_vec)\n",
        "    input_vec = tf.concat([input_vec, zeros_vec], axis=-1)\n",
        "    print('check: ', input_vec) # BxH\n",
        "    # reshape the input_vec\n",
        "    # input_vec = tf.transpose(tf.expand_dims(input_vec, axis=-1)) #\n",
        "    input_vec = tf.reshape(input_vec, [input_vec.shape[0], repeat+1, res_dim])\n",
        "    input_vec = tf.transpose(input_vec, perm=[0, 2, 1])\n",
        "    # input_vec = tf.squeeze(input_vec, axis=-1)\n",
        "    print('check reshape: ', input_vec.shape) # B x H x r\n",
        "    input_vec = tf.roll(input_vec, shift=[rot_num, 0], axis=[1, 2])\n",
        "    print('after roll: ', input_vec, tf.transpose(in_wt_vector))\n",
        "    proj_vec = tf.math.reduce_sum(input_vec*tf.transpose(in_wt_vector), axis=-1) # sum[(Hxr) * (Hxr)]\n",
        "    #print(proj_vec)\n",
        "    #proj_vec = input_vec\n",
        "\n",
        "  # rotate the input embeddings and return the hadamard product\n",
        "  return proj_vec  # [?, H]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yn0AvK4I3pZ",
        "colab_type": "code",
        "colab": {
          "height": 300
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1591421540964,
          "user_tz": 240,
          "elapsed": 1057,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "a0fe3876-16e6-4a48-d389-febd8383f5e1"
      },
      "source": [
        "# Individual vectors: inefficient implementation of ESN basis idea\n",
        "def _reservoir_out(hidden_vec, res_wt_vector, rot_num):\n",
        "  print('res_out: ', hidden_vec, res_wt_vector, rot_num, hidden_vec.shape,\n",
        "        res_wt_vector.shape)\n",
        "  # rotate the hidden vector and return the hadamard product\n",
        "  hidden_vec = tf.roll(hidden_vec, shift=[0, rot_num], axis=[0, 1])\n",
        "  print('res out 2: ', res_wt_vector*hidden_vec)\n",
        "  return res_wt_vector*hidden_vec  # [?, H]\n",
        "\n",
        "def _projection_out(input_vec, in_wt_vector, rot_num, in_dim, res_dim):\n",
        "  print('proj out :', input_vec, in_wt_vector, rot_num, input_vec.shape,\n",
        "        in_wt_vector.shape)\n",
        "  print('shape check : ', res_dim, in_dim)\n",
        "  # case I:  res_dim >= in_dim\n",
        "  if res_dim >= in_dim :\n",
        "    # concat inputs to match the res_sim\n",
        "    repeat = math.ceil(res_dim / in_dim) - 1 \n",
        "    print('repeat: ', repeat)\n",
        "    for i in range(repeat):\n",
        "      if i == repeat - 1:\n",
        "        input_vec = tf.concat([input_vec, input_vec[:, :(res_dim-repeat*(in_dim-1)-1)]], \n",
        "                              axis=-1)\n",
        "      else:\n",
        "        input_vec = tf.concat([input_vec, input_vec], axis=-1)\n",
        "    # rotate the input_vec\n",
        "    input_vec = tf.roll(input_vec, shift=[0, rot_num], axis=[-2, -1])\n",
        "    print('final in vec: ', input_vec, in_wt_vector)\n",
        "    proj_vec = in_wt_vector * input_vec\n",
        "  else: # Case II: res_dim < in_dim\n",
        "    repeat = math.ceil(in_dim/res_dim)-1\n",
        "    print('repeat num :', repeat, res_dim, in_dim, input_vec.shape)\n",
        "    # pad zeros\n",
        "    zeros_vec = tf.zeros([input_vec.shape[0], in_dim-repeat*(res_dim-1)-1])\n",
        "    # zeros_vec = tf.zeros([in_dim-repeat*(res_dim-1)-1])\n",
        "    print('zeros: ', zeros_vec, input_vec)\n",
        "    input_vec = tf.concat([input_vec, zeros_vec], axis=-1)\n",
        "    print('check: ', input_vec) # BxH\n",
        "    # reshape the input_vec\n",
        "    # input_vec = tf.transpose(tf.expand_dims(input_vec, axis=-1)) #\n",
        "    input_vec = tf.reshape(input_vec, [input_vec.shape[0], repeat+1, res_dim])\n",
        "    input_vec = tf.transpose(input_vec, perm=[0, 2, 1])\n",
        "    # input_vec = tf.squeeze(input_vec, axis=-1)\n",
        "    print('check reshape: ', input_vec.shape) # B x H x r\n",
        "    input_vec = tf.roll(input_vec, shift=[rot_num, 0], axis=[1, 2])\n",
        "    print('after roll: ', input_vec, tf.transpose(in_wt_vector))\n",
        "    proj_vec = tf.math.reduce_sum(input_vec*tf.transpose(in_wt_vector), axis=-1) # sum[(Hxr) * (Hxr)]\n",
        "    #print(proj_vec)\n",
        "    #proj_vec = input_vec\n",
        "\n",
        "  # rotate the input embeddings and return the hadamard product\n",
        "  return proj_vec  # [?, H]\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  res_dim, in_dim = 4, 6# 6, 4\n",
        "  if res_dim >= in_dim:\n",
        "    repeat_dim = 1\n",
        "  else:\n",
        "    print('res_dim < in_dim', in_dim/res_dim, math.ceil(in_dim/res_dim))\n",
        "    repeat_dim = math.ceil(in_dim/res_dim)\n",
        "  B = 3 # batch size\n",
        "  hidden_vec = tf.random.normal([B, res_dim], seed=9)\n",
        "  res_wt_vector = tf.ones([1, res_dim])*10\n",
        "  \n",
        "  roll_hidden_vec = tf.roll(hidden_vec, shift=[0, 2], axis=[0, 1])\n",
        "  \n",
        "  input_vec = tf.random.normal([B, in_dim], seed=9)\n",
        "  in_wt_vector = tf.ones([repeat_dim, res_dim])*10\n",
        "\n",
        "  # tf.print(x1)\n",
        "  rot=1\n",
        "  z1 = _reservoir_out(hidden_vec, res_wt_vector, rot)\n",
        "  z2 = _projection_out(input_vec, in_wt_vector, rot, in_dim, res_dim)\n",
        "  #cz1 = tf.concat([x1, y1], axis=-1)\n",
        "  # print_op = tf.print(\"reservoir_out:\", hidden_vec, roll_hidden_vec, res_wt_vector, z1, z1.shape,\n",
        "  #                         output_stream=sys.stdout)  \n",
        "  print_op = tf.print(\"projection_out:\", input_vec, in_wt_vector, z2, z2.shape,\n",
        "                          output_stream=sys.stdout)  \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "res_dim < in_dim 1.5 2\n",
            "res_out:  Tensor(\"random_normal_288:0\", shape=(3, 4), dtype=float32) Tensor(\"mul_739:0\", shape=(1, 4), dtype=float32) 1 (3, 4) (1, 4)\n",
            "res out 2:  Tensor(\"mul_741:0\", shape=(3, 4), dtype=float32)\n",
            "proj out : Tensor(\"random_normal_289:0\", shape=(3, 6), dtype=float32) Tensor(\"mul_740:0\", shape=(2, 4), dtype=float32) 1 (3, 6) (2, 4)\n",
            "shape check :  4 6\n",
            "repeat num : 1 4 6 (3, 6)\n",
            "zeros:  Tensor(\"zeros_115:0\", shape=(3, 2), dtype=float32) Tensor(\"random_normal_289:0\", shape=(3, 6), dtype=float32)\n",
            "check:  Tensor(\"concat_121:0\", shape=(3, 8), dtype=float32)\n",
            "check reshape:  (3, 4, 2)\n",
            "after roll:  Tensor(\"Roll_359:0\", shape=(3, 4, 2), dtype=float32) Tensor(\"transpose_137:0\", shape=(4, 2), dtype=float32)\n",
            "projection_out: [[1.15507281 -0.491057307 0.444480509 -2.43835855 -1.99601936 -0.484241098]\n",
            " [-0.491944462 0.527831 1.04352212 3.02801514 -0.460363448 0.412836105]\n",
            " [-0.254990488 -0.215089872 0.964658678 -1.62505496 0.61068213 0.71541]] [[10 10 10 10]\n",
            " [10 10 10 10]] [[-24.383585 -8.40946579 -9.75298405 4.44480515]\n",
            " [30.2801514 -9.52307892 9.40667152 10.4352207]\n",
            " [-16.2505493 3.55691624 5.00320148 9.64658642]] TensorShape([Dimension(3), Dimension(4)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBTKc9V6Pz4k",
        "colab_type": "code",
        "colab": {
          "height": 230
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1591675770644,
          "user_tz": 240,
          "elapsed": 1884,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "0b7d4956-e983-47b0-d685-9515ffa38aeb"
      },
      "source": [
        "# vectorized implementation for the ESN basis idea\n",
        "def _reservoir_out_batch(hidden_vec, res_wt, res_dim):\n",
        "  # concatenate the hidden vector by rotating.\n",
        "  # hidden_vec_batch = tf.repeat(hidden_vec, repeats=[res_dim], axis=-2)\n",
        "  # hidden_vec_batch = tf.reshape(hidden_vec_batch, [-1, res_dim, *([1]*res_dim)])#, res_dim])# BxHxH\n",
        "  # # hidden_vec_batch = tf.transpose()\n",
        "  # print(list(range(0,res_dim)))\n",
        "  # hidden_vec_batch = tf.roll(hidden_vec_batch, shift=range(0, res_dim), axis=range(1, res_dim+1))#range(2, res_dim+2))\n",
        "  # print(hidden_vec_batch)\n",
        "  # hidden_vec_batch = tf.reshape(hidden_vec_batch, [-1, res_dim, res_dim])\n",
        "  # return hidden_vec_batch\n",
        "  hidden_vec_batch = []\n",
        "  for _ in range(res_dim):\n",
        "    hidden_vec = tf.roll(hidden_vec, shift=[0, 1], axis=[0, 1])\n",
        "    hidden_vec_batch.append(tf.expand_dims(hidden_vec, -1))\n",
        "  hidden_vec_batch = tf.concat(hidden_vec_batch, axis=-1)\n",
        "  return hidden_vec_batch * res_wt # [?, H, H]\n",
        "\n",
        "def _projection_out_batch(input_vec, in_wt, in_dim, res_dim):\n",
        "  if res_dim >= in_dim:  # case I:  res_dim >= in_dim\n",
        "    # concat inputs to match the res_sim\n",
        "    repeat = math.ceil(res_dim / in_dim) - 1 \n",
        "    print('repeat: ', repeat)\n",
        "    for i in range(repeat):\n",
        "      if i == repeat - 1:\n",
        "        input_vec = tf.concat([input_vec, input_vec[:, :(res_dim-repeat*(in_dim-1)-1)]], \n",
        "                              axis=-1)\n",
        "      else:\n",
        "        input_vec = tf.concat([input_vec, input_vec], axis=-1)\n",
        "    input_vec_batch = []\n",
        "    # rotate the input_vec\n",
        "    for _ in range(res_dim):\n",
        "      input_vec = tf.roll(input_vec, shift=[0, 1], axis=[-2, -1])\n",
        "      input_vec_batch.append(tf.expand_dims(input_vec, -1))\n",
        "    input_vec_batch = tf.concat(input_vec_batch, axis=-1)\n",
        "    print('final in vec: ', input_vec_batch, in_wt)\n",
        "    proj_vec = input_vec_batch * in_wt\n",
        "  else: # Case II: res_dim < in_dim -->  FIX\n",
        "    # 1. reapeat the input res_dim times with rot\n",
        "    # 2. Do the hadamard product 3. Reshape & tf.reduce ; return HxH \n",
        "    repeat = math.ceil(in_dim/res_dim)-1\n",
        "    print('repeat num :', repeat, res_dim, in_dim, input_vec.shape)\n",
        "    # # Step 1. pad zeros\n",
        "    # zeros_vec = tf.zeros([input_vec.shape[0], in_dim-repeat*(res_dim-1)-1])\n",
        "    # # zeros_vec = tf.zeros([in_dim-repeat*(res_dim-1)-1])\n",
        "    # print('zeros: ', zeros_vec, input_vec)\n",
        "    # input_vec = tf.concat([input_vec, zeros_vec], axis=-1)\n",
        "    print('check: ', input_vec) # BxI\n",
        "    # Step 1. concat the Input with rotation\n",
        "    input_vec_batch = []\n",
        "    for _ in range(res_dim):\n",
        "      input_vec = tf.roll(input_vec, shift=[0, 1], axis=[-2, -1])\n",
        "      input_vec_batch.append(tf.expand_dims(input_vec, -1))\n",
        "    input_vec_batch = tf.concat(input_vec_batch, axis=-1) # B x I x H\n",
        "    # Step 2. The Hadamard product\n",
        "    proj_vec_temp = input_vec_batch * in_wt # B x I x H\n",
        "    print('intermediate shape: ', proj_vec_temp.shape)\n",
        "    # Step 3. Reshape the proj_vec = B x H x H x (I/H)\n",
        "    pv_final1 = proj_vec_temp[:, :res_dim, :res_dim] # B x H x H\n",
        "    for r in range(1, in_dim//res_dim):\n",
        "      pv_final1 = pv_final1 + proj_vec_temp[:, r*res_dim:(r+1)*res_dim, :res_dim]\n",
        "    print('pv final1 shape: ', pv_final1.shape)\n",
        "    if in_dim % res_dim != 0: # last part, pad zeros and add\n",
        "      pv_final2 = proj_vec_temp[:, res_dim*(in_dim//res_dim):in_dim, :res_dim] # B x (I-H*r) x H\n",
        "      paddings = tf.constant([[1,1,1], [1, 1, 2]])\n",
        "      pv_final2 = tf.pad(pv_final2, paddings, mode='CONSTANT', name=None)\n",
        "    proj_vec = pv_final2 #pv_final1 + pv_final2\n",
        "\n",
        "    # proj_vec = tf.reshape(proj_vec, [-1, res_dim, res_dim, in_dim/res_dim])\n",
        "    # Step 4. Reduce using tf.sum and squeeze\n",
        "    # proj_vec = tf.math.reduce_sum(proj_vec, axis=-1)\n",
        "\n",
        "    # # input_vec = tf.transpose(tf.expand_dims(input_vec, axis=-1)) #\n",
        "    # input_vec = tf.reshape(input_vec, [input_vec.shape[0], repeat+1, res_dim])\n",
        "    # input_vec = tf.transpose(input_vec, perm=[0, 2, 1])\n",
        "    # # input_vec = tf.squeeze(input_vec, axis=-1)\n",
        "    # print('check reshape: ', input_vec.shape) # B x H x r\n",
        "    # #for _ in range(res_dim):\n",
        "    # input_vec = tf.roll(input_vec, shift=[rot_num, 0], axis=[1, 2])\n",
        "    # print('after roll: ', input_vec, tf.transpose(in_wt_vector))\n",
        "    # proj_vec = tf.math.reduce_sum(input_vec*tf.transpose(in_wt_vector), axis=-1) # sum[(Hxr) * (Hxr)]\n",
        "    # #print(proj_vec)\n",
        "    # #proj_vec = input_vec\n",
        "  return proj_vec\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  res_dim, in_dim = 4, 6# 6, 4\n",
        "  if res_dim >= in_dim:\n",
        "    in_wt_dim = res_dim\n",
        "  else:\n",
        "    print('res_dim < in_dim', in_dim/res_dim, math.ceil(in_dim/res_dim))\n",
        "    # repeat_dim = math.ceil(in_dim/res_dim)\n",
        "    # in_wt_dim = math.ceil(in_dim/res_dim) * res_dim \n",
        "    in_wt_dim = in_dim\n",
        "  B = 1 # batch size\n",
        "  hidden_vec = tf.random.normal([B, res_dim], seed=9)\n",
        "  res_wt = tf.ones([res_dim, res_dim])*10\n",
        "  \n",
        "  roll_hidden_vec = tf.roll(hidden_vec, shift=[0, 2], axis=[0, 1])\n",
        "  \n",
        "  input_vec = tf.random.normal([B, in_dim], seed=9)\n",
        "  # in_wt = tf.ones([res_dim*repeat_dim, res_dim])*10\n",
        "  in_wt = tf.ones([in_wt_dim, res_dim])*10\n",
        "\n",
        "  # tf.print(x1)\n",
        "  # rot=1\n",
        "  # z1 = _reservoir_out_batch(hidden_vec, res_wt, res_dim)\n",
        "  z2 = _projection_out_batch(input_vec, in_wt, in_dim, res_dim)\n",
        "  #cz1 = tf.concat([x1, y1], axis=-1)\n",
        "  # print_op = tf.print(\"reservoir_out:\", hidden_vec, res_wt, z1, z1.shape,\n",
        "  #                       output_stream=sys.stdout)  \n",
        "  print_op = tf.print(\"projection_out:\", input_vec, in_wt, z2, z2.shape,\n",
        "                         output_stream=sys.stdout)  \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "res_dim < in_dim 1.5 2\n",
            "repeat num : 1 4 6 (1, 6)\n",
            "check:  Tensor(\"random_normal_515:0\", shape=(1, 6), dtype=float32)\n",
            "intermediate shape:  (1, 6, 4)\n",
            "pv final1 shape:  (1, 4, 4)\n",
            "projection_out: [[1.15507281 -0.491057307 0.444480509 -2.43835855 -1.99601936 -0.484241098]] [[10 10 10 10]\n",
            " [10 10 10 10]\n",
            " [10 10 10 10]\n",
            " [10 10 10 10]\n",
            " [10 10 10 10]\n",
            " [10 10 10 10]] [[[-24.383585 4.44480515 -4.91057301 11.5507278]\n",
            "  [-19.9601936 -24.383585 4.44480515 -4.91057301]]] TensorShape([Dimension(1), Dimension(2), Dimension(4)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYA5Iqyajrmo",
        "colab_type": "code",
        "colab": {
          "height": 167
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275605381,
          "user_tz": 240,
          "elapsed": 687,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "47932d7a-b2e2-4c08-8e4e-7ca45af85767"
      },
      "source": [
        "# vectorized implementation for the ESN basis idea: 3D mat\n",
        "def _reservoir_out_batch3D(hidden_vec, res_wt, res_dim):\n",
        "  # concatenate the hidden vector by rotating.\n",
        "  # hidden_vec_batch = tf.repeat(hidden_vec, repeats=[res_dim], axis=-2)\n",
        "  # hidden_vec_batch = tf.reshape(hidden_vec_batch, [-1, res_dim, *([1]*res_dim)])#, res_dim])# BxHxH\n",
        "  # # hidden_vec_batch = tf.transpose()\n",
        "  # print(list(range(0,res_dim)))\n",
        "  # hidden_vec_batch = tf.roll(hidden_vec_batch, shift=range(0, res_dim), axis=range(1, res_dim+1))#range(2, res_dim+2))\n",
        "  # print(hidden_vec_batch)\n",
        "  # hidden_vec_batch = tf.reshape(hidden_vec_batch, [-1, res_dim, res_dim])\n",
        "  # return hidden_vec_batch\n",
        "\n",
        "  hidden_vec_batch = []\n",
        "  for _ in range(res_dim):\n",
        "    hidden_vec = tf.roll(hidden_vec, shift=[0, 1], axis=[0, 1])\n",
        "    hidden_vec_batch.append(tf.expand_dims(hidden_vec, -1))\n",
        "  hidden_vec_batch = tf.concat(hidden_vec_batch, axis=-1)\n",
        "  return hidden_vec_batch * res_wt # [?, H, H]\n",
        "\n",
        "  # def all_shifts(vector):\n",
        "  #   length = tf.size(vector)\n",
        "  #   repeated = tf.tile(vector, [vector.shape[0], length+1])  # [vector.shape[0],, length+1]\n",
        "  #   print(repeated)\n",
        "  #   return tf.reshape(repeated, [length, length+1])[:, :length]\n",
        "\n",
        "  # return all_shifts(hidden_vec) * res_wt\n",
        "\n",
        "def _projection_out_batch3D(input_vec, in_wt, in_dim, res_dim):\n",
        "  if res_dim >= in_dim:  # case I:  res_dim >= in_dim\n",
        "    # concat inputs to match the res_sim\n",
        "    repeat = math.ceil(res_dim / in_dim) - 1 \n",
        "    print('repeat: ', repeat)\n",
        "    for i in range(repeat):\n",
        "      if i == repeat - 1:\n",
        "        input_vec = tf.concat([input_vec, input_vec[:, :(res_dim-repeat*(in_dim-1)-1)]], \n",
        "                              axis=-1)\n",
        "      else:\n",
        "        input_vec = tf.concat([input_vec, input_vec], axis=-1)\n",
        "    input_vec_batch = []\n",
        "    # rotate the input_vec\n",
        "    for _ in range(res_dim):\n",
        "      input_vec = tf.roll(input_vec, shift=[0, 1], axis=[-2, -1])\n",
        "      input_vec_batch.append(tf.expand_dims(input_vec, -1))\n",
        "    input_vec_batch = tf.concat(input_vec_batch, axis=-1)\n",
        "    print('final in vec: ', input_vec_batch, in_wt)\n",
        "    proj_vec = input_vec_batch * in_wt\n",
        "  else: # Case II: res_dim < in_dim -->  FIX\n",
        "    # 1. reapeat the input res_dim times with rot\n",
        "    # 2. Do the hadamard product 3. Reshape & tf.reduce ; return HxH \n",
        "    repeat = math.ceil(in_dim/res_dim)-1\n",
        "    print('repeat num :', repeat, res_dim, in_dim, input_vec.shape)\n",
        "    # # Step 1. pad zeros\n",
        "    # zeros_vec = tf.zeros([input_vec.shape[0], in_dim-repeat*(res_dim-1)-1])\n",
        "    # # zeros_vec = tf.zeros([in_dim-repeat*(res_dim-1)-1])\n",
        "    # print('zeros: ', zeros_vec, input_vec)\n",
        "    # input_vec = tf.concat([input_vec, zeros_vec], axis=-1)\n",
        "    print('check: ', input_vec) # BxI\n",
        "    # Step 1. concat the Input with rotation\n",
        "    input_vec_batch = []\n",
        "    for _ in range(res_dim):\n",
        "      input_vec = tf.roll(input_vec, shift=[0, 1], axis=[-2, -1])\n",
        "      input_vec_batch.append(tf.expand_dims(input_vec, -1))\n",
        "    input_vec_batch = tf.concat(input_vec_batch, axis=-1) # B x I x H\n",
        "    # Step 2. The Hadamard product\n",
        "    proj_vec_temp = input_vec_batch * in_wt # B x I x H\n",
        "    print('intermediate shape: ', proj_vec_temp.shape)\n",
        "    # Step 3. Reshape the proj_vec = B x H x H x (I/H)\n",
        "    pv_final1 = proj_vec_temp[:, :res_dim, :res_dim] # B x H x H\n",
        "    for r in range(1, in_dim//res_dim):\n",
        "      pv_final1 = pv_final1 + proj_vec_temp[:, r*res_dim:(r+1)*res_dim, :res_dim]\n",
        "    print('pv final1 shape: ', pv_final1.shape)\n",
        "    if in_dim % res_dim != 0: # last part, pad zeros and add\n",
        "      pv_final2 = proj_vec_temp[:, res_dim*(in_dim//res_dim):in_dim, :res_dim] # B x (I-H*r) x H\n",
        "      paddings = tf.constant([[1,1,1], [1, 1, 2]])\n",
        "      pv_final2 = tf.pad(pv_final2, paddings, mode='CONSTANT', name=None)\n",
        "    proj_vec = pv_final2 #pv_final1 + pv_final2\n",
        "\n",
        "    # proj_vec = tf.reshape(proj_vec, [-1, res_dim, res_dim, in_dim/res_dim])\n",
        "    # Step 4. Reduce using tf.sum and squeeze\n",
        "    # proj_vec = tf.math.reduce_sum(proj_vec, axis=-1)\n",
        "\n",
        "    # # input_vec = tf.transpose(tf.expand_dims(input_vec, axis=-1)) #\n",
        "    # input_vec = tf.reshape(input_vec, [input_vec.shape[0], repeat+1, res_dim])\n",
        "    # input_vec = tf.transpose(input_vec, perm=[0, 2, 1])\n",
        "    # # input_vec = tf.squeeze(input_vec, axis=-1)\n",
        "    # print('check reshape: ', input_vec.shape) # B x H x r\n",
        "    # #for _ in range(res_dim):\n",
        "    # input_vec = tf.roll(input_vec, shift=[rot_num, 0], axis=[1, 2])\n",
        "    # print('after roll: ', input_vec, tf.transpose(in_wt_vector))\n",
        "    # proj_vec = tf.math.reduce_sum(input_vec*tf.transpose(in_wt_vector), axis=-1) # sum[(Hxr) * (Hxr)]\n",
        "    # #print(proj_vec)\n",
        "    # #proj_vec = input_vec\n",
        "  return proj_vec\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  res_dim, in_dim = 4, 6# 6, 4\n",
        "  if res_dim >= in_dim:\n",
        "    in_wt_dim = res_dim\n",
        "  else:\n",
        "    print('res_dim < in_dim', in_dim/res_dim, math.ceil(in_dim/res_dim))\n",
        "    # repeat_dim = math.ceil(in_dim/res_dim)\n",
        "    # in_wt_dim = math.ceil(in_dim/res_dim) * res_dim \n",
        "    in_wt_dim = in_dim\n",
        "  B = 1 # batch size\n",
        "  hidden_vec = tf.random.normal([B, res_dim], seed=9)\n",
        "  res_wt = tf.ones([res_dim, res_dim])*10\n",
        "  \n",
        "  roll_hidden_vec = tf.roll(hidden_vec, shift=[0, 2], axis=[0, 1])\n",
        "  \n",
        "  input_vec = tf.random.normal([B, in_dim], seed=9)\n",
        "  # in_wt = tf.ones([res_dim*repeat_dim, res_dim])*10\n",
        "  in_wt = tf.ones([in_wt_dim, res_dim])*10\n",
        "\n",
        "  # tf.print(x1)\n",
        "  # rot=1\n",
        "  z1 = _reservoir_out_batch3D(hidden_vec, res_wt, res_dim)\n",
        "  # z2 = _projection_out_batch3D(input_vec, in_wt, in_dim, res_dim)\n",
        "  #cz1 = tf.concat([x1, y1], axis=-1)\n",
        "  print_op = tf.print(\"reservoir_out:\", hidden_vec, res_wt, z1, z1.shape,\n",
        "                        output_stream=sys.stdout)  \n",
        "  # print_op = tf.print(\"projection_out:\", input_vec, in_wt, z2, z2.shape,\n",
        "  #                        output_stream=sys.stdout)  \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "res_dim < in_dim 1.5 2\n",
            "reservoir_out: [[1.15507281 -0.491057307 0.444480509 -2.43835855]] [[10 10 10 10]\n",
            " [10 10 10 10]\n",
            " [10 10 10 10]\n",
            " [10 10 10 10]] [[[-24.383585 4.44480515 -4.91057301 11.5507278]\n",
            "  [11.5507278 -24.383585 4.44480515 -4.91057301]\n",
            "  [-4.91057301 11.5507278 -24.383585 4.44480515]\n",
            "  [4.44480515 -4.91057301 11.5507278 -24.383585]]] TensorShape([Dimension(1), Dimension(4), Dimension(4)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ixJQDMjNoFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWVrLx5vNn5K",
        "colab_type": "code",
        "colab": {
          "height": 633
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275629036,
          "user_tz": 240,
          "elapsed": 615,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "6341201f-d0fa-4c32-fe6d-800f40635bb9"
      },
      "source": [
        "# Basis3D \n",
        "def _reservoir_out_batch3D(hidden_vec, res_wt):\n",
        "  # hidden_vec = BxH and res_wt = HxHxnum_basis\n",
        "  # res_out = tf.matmul(hidden_vec, res_wt)\n",
        "  print('shapes: ', hidden_vec.shape, res_wt.shape)\n",
        "  # res_out = tf.matmul(hidden_vec, res_wt)\n",
        "\n",
        "  res_wt = tf.transpose(res_wt, perm=[2,1,0]) # num_basis x H x H\n",
        "  res_out = tf.matmul(res_wt, tf.transpose(hidden_vec))\n",
        "  res_out = tf.transpose(res_out, perm=[2,1,0])\n",
        "  return res_out # [B, H, num_basis]\n",
        "\n",
        "def _projection_out_batch3D(input_vec, in_wt):\n",
        "  # input_vec = BxI and in_wt = IxHxnum_basis\n",
        "  # proj_out = tf.matmul(input_vec, in_wt)\n",
        "\n",
        "  proj_out = tf.matmul(tf.transpose(in_wt, perm=[2,1,0]), tf.transpose(input_vec))\n",
        "  proj_out = tf.transpose(proj_out, perm=[2,1,0])\n",
        "  return proj_out # [B, H, num_basis]\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  res_dim, in_dim = 4, 6# 6, 4\n",
        "\n",
        "  num_basis = 3\n",
        "\n",
        "  B = 2 # batch size\n",
        "  hidden_vec = tf.random.normal([B, res_dim], seed=9)\n",
        "  res_wt = tf.ones([res_dim, res_dim, num_basis])*10\n",
        "  # Create the mask for the reservoir basis matrix\n",
        "  mask3D = []\n",
        "  for rot in range(num_basis):\n",
        "    _w_scr = tf.linalg.diag(tf.ones(res_dim))\n",
        "    w_scr = tf.roll(_w_scr, shift=[rot, 0], axis=[0, 1])\n",
        "    mask = w_scr # tf.cast(w_scr, dtype=dtype)\n",
        "    print(mask.shape)\n",
        "    mask3D.append(tf.expand_dims(mask, -1))\n",
        "  mask = tf.concat(mask3D, axis=-1)\n",
        "  \n",
        "  res_wt = res_wt * mask\n",
        "  \n",
        "  input_vec = tf.random.normal([B, in_dim], seed=9)\n",
        "  # in_wt = tf.ones([res_dim*repeat_dim, res_dim])*10\n",
        "  in_wt = tf.ones([in_wt_dim, res_dim, num_basis])*10\n",
        "  mask3D = []\n",
        "  for rot in range(num_basis):\n",
        "    dim0, dim1 = in_dim, res_dim\n",
        "    if dim0 <= dim1:\n",
        "      shape0, shape1 = dim0, dim1\n",
        "      do_transpose = False\n",
        "    else:\n",
        "      shape0, shape1 = dim1, dim0\n",
        "      do_transpose = True\n",
        "    # assuming shape0 < shape1:\n",
        "    repeat = math.ceil(shape1 / shape0) - 1\n",
        "    w_scr = tf.eye(shape0)\n",
        "    for i in range(repeat):\n",
        "      if i == repeat - 1:  # truncate\n",
        "        w_diag = tf.eye(shape0)\n",
        "        w_scr = tf.concat([w_scr, w_diag[:, :(shape1 - shape0)]], axis=1)\n",
        "      else:\n",
        "        w_scr = tf.concat([w_scr, tf.eye(shape0)], axis=1)\n",
        "    w_scr = tf.roll(w_scr, shift=[rot, 0], axis=[0, 1])\n",
        "    # the transpose condition\n",
        "    if do_transpose:\n",
        "      w_scr = tf.transpose(w_scr, perm=[1, 0])\n",
        "    mask = w_scr #tf.cast(w_scr, dtype=dtype)\n",
        "    mask3D.append(tf.expand_dims(mask, -1))\n",
        "  mask = tf.concat(mask3D, axis=-1)\n",
        "  print('in mask: ', mask.shape)\n",
        "  in_wt = in_wt * mask\n",
        "  # v = in_wt\n",
        "  # v_norm2 = tf.sqrt(tf.reduce_sum(tf.square(v)))\n",
        "  # is_norm_0 = tf.equal(v_norm2, 0)\n",
        "  # print(is_norm_0)\n",
        "  # v = v * 1.0/(v_norm2 +is_norm_0)\n",
        "  # print(v.shape)\n",
        "\n",
        "  z1 = _reservoir_out_batch3D(hidden_vec, res_wt)\n",
        "  print_op = tf.print(\"reservoir_out:\", hidden_vec, res_wt, z1, z1.shape,\n",
        "                        output_stream=sys.stdout)\n",
        "  \n",
        "  # z2 = _projection_out_batch3D(input_vec, in_wt)\n",
        "  # print_op = tf.print(\"projection_out:\", input_vec, in_wt, z2, z2.shape,\n",
        "  #                        output_stream=sys.stdout)  \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 4)\n",
            "(4, 4)\n",
            "(4, 4)\n",
            "in mask:  (6, 4, 3)\n",
            "shapes:  (2, 4) (4, 4, 3)\n",
            "reservoir_out: [[1.15507281 -0.491057307 0.444480509 -2.43835855]\n",
            " [-1.99601936 -0.484241098 -0.491944462 0.527831]] [[[10 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 10]\n",
            "  [0 10 0]]\n",
            "\n",
            " [[0 10 0]\n",
            "  [10 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 10]]\n",
            "\n",
            " [[0 0 10]\n",
            "  [0 10 0]\n",
            "  [10 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 10]\n",
            "  [0 10 0]\n",
            "  [10 0 0]]] [[[11.5507278 -4.91057301 4.44480515]\n",
            "  [-4.91057301 4.44480515 -24.383585]\n",
            "  [4.44480515 -24.383585 11.5507278]\n",
            "  [-24.383585 11.5507278 -4.91057301]]\n",
            "\n",
            " [[-19.9601936 -4.84241104 -4.91944456]\n",
            "  [-4.84241104 -4.91944456 5.2783103]\n",
            "  [-4.91944456 5.2783103 -19.9601936]\n",
            "  [5.2783103 -19.9601936 -4.84241104]]] TensorShape([Dimension(2), Dimension(4), Dimension(3)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iw7bb8QavP3",
        "colab_type": "code",
        "colab": {
          "height": 1000
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595276262884,
          "user_tz": 240,
          "elapsed": 454,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "85721604-c263-4002-e3c1-604a3d65bad0"
      },
      "source": [
        "# Basis3D \n",
        "def _reservoir_out_batch3D(hidden_vec, res_wt):\n",
        "  # hidden_vec = BxH and res_wt = HxHxnum_basis\n",
        "  # res_out = tf.matmul(hidden_vec, res_wt)\n",
        "  print('shapes: ', hidden_vec.shape, res_wt.shape)\n",
        "  # res_out = tf.matmul(hidden_vec, res_wt)\n",
        "\n",
        "  res_wt = tf.transpose(res_wt, perm=[2,1,0]) # num_basis x H x H\n",
        "  res_out = tf.matmul(res_wt, tf.transpose(hidden_vec)) # num_basis x H x B\n",
        "  res_out = tf.transpose(res_out, perm=[2,1,0])\n",
        "  return res_out # [B, H, num_basis]\n",
        "\n",
        "def _projection_out_batch3D(input_vec, in_wt):\n",
        "  # input_vec = BxI and in_wt = IxHxnum_basis\n",
        "  # proj_out = tf.matmul(input_vec, in_wt)\n",
        "\n",
        "  proj_out = tf.matmul(tf.transpose(in_wt, perm=[2,1,0]), tf.transpose(input_vec))\n",
        "  proj_out = tf.transpose(proj_out, perm=[2,1,0])\n",
        "  return proj_out # [B, H, num_basis]\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  res_dim, in_dim = 4, 6# 6, 4\n",
        "\n",
        "  num_basis = 3\n",
        "\n",
        "  B = 2 # batch size\n",
        "  hidden_vec = tf.random.normal([B, res_dim], seed=9)\n",
        "  res_wt = tf.ones([res_dim, res_dim, num_basis])*10\n",
        "  # Create the mask for the reservoir basis matrix\n",
        "  mask3D = []\n",
        "  for rot in range(num_basis):\n",
        "    _w_scr = tf.linalg.diag(tf.ones(res_dim))\n",
        "    w_scr = tf.roll(_w_scr, shift=[rot, 0], axis=[0, 1])\n",
        "    mask = w_scr # tf.cast(w_scr, dtype=dtype)\n",
        "    print(mask.shape)\n",
        "    mask3D.append(tf.expand_dims(mask, -1))\n",
        "  mask = tf.concat(mask3D, axis=-1)\n",
        "  \n",
        "  res_wt = res_wt * mask\n",
        "\n",
        "  z1 = _reservoir_out_batch3D(hidden_vec, res_wt)\n",
        "  print_op = tf.print(\"reservoir_out:\", hidden_vec, tf.transpose(mask, perm=[2,1,0]), res_wt, z1, z1.shape,\n",
        "                        output_stream=sys.stdout)\n",
        "   \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 6)\n",
            "(6, 6)\n",
            "(6, 6)\n",
            "shapes:  (2, 6) (6, 6, 3)\n",
            "reservoir_out: [[1.15507281 -0.491057307 0.444480509 -2.43835855 -1.99601936 -0.484241098]\n",
            " [-0.491944462 0.527831 1.04352212 3.02801514 -0.460363448 0.412836105]] [[[1 0 0 0 0 0]\n",
            "  [0 1 0 0 0 0]\n",
            "  [0 0 1 0 0 0]\n",
            "  [0 0 0 1 0 0]\n",
            "  [0 0 0 0 1 0]\n",
            "  [0 0 0 0 0 1]]\n",
            "\n",
            " [[0 1 0 0 0 0]\n",
            "  [0 0 1 0 0 0]\n",
            "  [0 0 0 1 0 0]\n",
            "  [0 0 0 0 1 0]\n",
            "  [0 0 0 0 0 1]\n",
            "  [1 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 1 0 0 0]\n",
            "  [0 0 0 1 0 0]\n",
            "  [0 0 0 0 1 0]\n",
            "  [0 0 0 0 0 1]\n",
            "  [1 0 0 0 0 0]\n",
            "  [0 1 0 0 0 0]]] [[[10 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 10]\n",
            "  [0 10 0]]\n",
            "\n",
            " [[0 10 0]\n",
            "  [10 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 10]]\n",
            "\n",
            " [[0 0 10]\n",
            "  [0 10 0]\n",
            "  [10 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 10]\n",
            "  [0 10 0]\n",
            "  [10 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 10]\n",
            "  [0 10 0]\n",
            "  [10 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 10]\n",
            "  [0 10 0]\n",
            "  [10 0 0]]] [[[11.5507278 -4.91057301 4.44480515]\n",
            "  [-4.91057301 4.44480515 -24.383585]\n",
            "  [4.44480515 -24.383585 -19.9601936]\n",
            "  [-24.383585 -19.9601936 -4.84241104]\n",
            "  [-19.9601936 -4.84241104 11.5507278]\n",
            "  [-4.84241104 11.5507278 -4.91057301]]\n",
            "\n",
            " [[-4.91944456 5.2783103 10.4352207]\n",
            "  [5.2783103 10.4352207 30.2801514]\n",
            "  [10.4352207 30.2801514 -4.60363436]\n",
            "  [30.2801514 -4.60363436 4.12836123]\n",
            "  [-4.60363436 4.12836123 -4.91944456]\n",
            "  [4.12836123 -4.91944456 5.2783103]]] TensorShape([Dimension(2), Dimension(6), Dimension(3)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqFnbUbzZMxk",
        "colab_type": "code",
        "colab": {
          "height": 35
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1591934745645,
          "user_tz": 240,
          "elapsed": 1530,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "b80e1fe5-ca90-492e-d84b-d63f490416f8"
      },
      "source": [
        "res_wt = tf.ones([4, 4, 4])\n",
        "scalar_vec = tf.constant([2,10,200.0,1000])\n",
        "scalar_vec = tf.reshape(scalar_vec, [1, 4])\n",
        "res_scalar = tf.multiply(scalar_vec, res_wt)\n",
        "print(res_scalar, res_wt)\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  result = sess.run([res_scalar, res_wt, scalar_vec])\n",
        "  #print([:, :, 0])#, res_wt[:, :, 2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mul_1318:0\", shape=(4, 4, 4), dtype=float32) Tensor(\"ones_814:0\", shape=(4, 4, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toDTwPF3p93b",
        "colab_type": "code",
        "colab": {
          "height": 247
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1591934748738,
          "user_tz": 240,
          "elapsed": 410,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "44f276f6-cf03-4298-f24c-3f1857b62262"
      },
      "source": [
        "print(result[0][:, :,0], result[0][:, :, 2], result[1][:,:,0], result[1][:,:,2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2. 2. 2. 2.]\n",
            " [2. 2. 2. 2.]\n",
            " [2. 2. 2. 2.]\n",
            " [2. 2. 2. 2.]] [[200. 200. 200. 200.]\n",
            " [200. 200. 200. 200.]\n",
            " [200. 200. 200. 200.]\n",
            " [200. 200. 200. 200.]] [[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]] [[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LTifHisrnhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def all_shifts(vector):\n",
        "    length = tf.size(vector)\n",
        "    repeated = tf.tile(vector, [length+1])\n",
        "    return tf.reshape(repeated, [length, length+1])[:, :length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFi7XiNu-t8_",
        "colab_type": "code",
        "colab": {
          "height": 249
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1595275064104,
          "user_tz": 240,
          "elapsed": 954,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "d8377c06-9114-4fb9-b8e4-d8e2c7de7288"
      },
      "source": [
        "# Basis efficient implementation\n",
        "def all_shifts(hidden_state, H):\n",
        "  # H = hidden_vec.shape[-1]\n",
        "  repeated = tf.tile(hidden_state, [1,H+1])\n",
        "  out = tf.reshape(repeated, [-1, H, H+1])[:,:,:H]\n",
        "  return out\n",
        "\n",
        "def _reservoir_out(hidden_vec, res_wt, res_dim):\n",
        "  print('shapes: ', hidden_vec.shape, res_wt.shape)\n",
        "  return all_shifts(hidden_vec, res_dim) * res_wt\n",
        "\n",
        "def _projection_out(input_vec, in_wt, in_dim, res_dim):\n",
        "  if res_dim >= in_dim:  # case I:  res_dim >= in_dim\n",
        "    # concat inputs to match the res_sim\n",
        "    repeat = math.ceil(res_dim / in_dim) - 1 \n",
        "    print('repeat: ', repeat, res_dim, in_dim, input_vec.shape)\n",
        "    for i in range(repeat):\n",
        "      if i == repeat - 1:\n",
        "        # input_vec = tf.concat([input_vec, input_vec[:, :(res_dim-repeat*(in_dim-1)-1)]], \n",
        "        #                       axis=-1)\n",
        "        input_vec = tf.concat([input_vec, input_vec[:, :(res_dim-(repeat*in_dim))]], \n",
        "                              axis=-1)\n",
        "      else:\n",
        "        input_vec = tf.concat([input_vec, input_vec], axis=-1)\n",
        "    print('input vec: ', input_vec.shape)\n",
        "    input_vec_batch = all_shifts(input_vec, res_dim)\n",
        "    print('final in vec: ', input_vec_batch, in_wt)\n",
        "    proj_vec = input_vec_batch * in_wt\n",
        "  else: # Case II: res_dim < in_dim -->  FIX\n",
        "    print('Case res_dim < in_dim not implemented', res_dim, in_dim)\n",
        "  return proj_vec\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  res_dim, in_dim = 4, 4# 6, 4\n",
        "\n",
        "  num_basis = res_dim #3\n",
        "\n",
        "  B = 2 # batch size\n",
        "  hidden_vec = tf.random.normal([B, res_dim], seed=9)\n",
        "  res_wt = tf.ones([num_basis, res_dim])*10\n",
        "\n",
        "  # z1 = _reservoir_out(hidden_vec, res_wt, res_dim)\n",
        "  # print_op = tf.print(\"reservoir_out:\", hidden_vec, res_wt, z1, z1.shape,\n",
        "  #                       output_stream=sys.stdout)\n",
        "  input_vec = tf.random.normal([B, in_dim], seed=10)\n",
        "  in_wt = tf.ones([num_basis, res_dim])*10\n",
        "  z2 = _projection_out(input_vec, in_wt, in_dim, res_dim)\n",
        "  print_op = tf.print(\"projection_out:\", input_vec, in_wt, z2, z2.shape,\n",
        "                         output_stream=sys.stdout) \n",
        "  \n",
        "  with tf.control_dependencies([print_op]):  \n",
        "    tripled_tensor =z1* 3  \n",
        "  sess.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-8b98cdefaa05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mproj_vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[0mres_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;31m# 6, 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByO3R6ZL_JkU",
        "colab_type": "code",
        "colab": {
          "height": 106
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592007802686,
          "user_tz": 240,
          "elapsed": 1539,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "3e396482-d76b-43f6-89d8-94a2f7a52a49"
      },
      "source": [
        "def all_shifts(vector):\n",
        "  length = tf.size(vector)\n",
        "  repeated = tf.tile(vector, [length+1])\n",
        "  # out = tf.reshape(repeated, [length, length+1])[:, :length]\n",
        "  out = tf.reshape(repeated, [length, length+1])\n",
        "  return repeated, out\n",
        "\n",
        "h = tf.constant([1,2,3,4])\n",
        "repeated, out = all_shifts(h)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  res = sess.run([repeated, out])\n",
        "  print(res)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
            "      dtype=int32), array([[1, 2, 3, 4, 1],\n",
            "       [2, 3, 4, 1, 2],\n",
            "       [3, 4, 1, 2, 3],\n",
            "       [4, 1, 2, 3, 4]], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GfE_fVlDYiD",
        "colab_type": "code",
        "colab": {
          "height": 212
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592010484431,
          "user_tz": 240,
          "elapsed": 2216,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "ba68d1c6-1a5e-42d7-a175-83e53e4899f0"
      },
      "source": [
        "H = 4 # hidden size\n",
        "B = 2 # batch size\n",
        "\n",
        "def all_shifts(hidden_state):\n",
        "  repeated = tf.tile(hidden_state, [1,H+1])\n",
        "  # out = tf.reshape(repeated, [length, length+1])[:, :length]\n",
        "  # out = tf.reshape(repeated, [length, length+1])\n",
        "  out = tf.reshape(repeated, [-1, H, H+1])[:,:,:H]\n",
        "  return repeated, out\n",
        "\n",
        "\n",
        "h = tf.reshape(tf.range(8),[B,H])\n",
        "# h = tf.constant([[0,1,2,3],[4,5,6,7]])\n",
        "repeated, out = all_shifts(h)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  res = sess.run([repeated, out])\n",
        "  print(res[0], res[0].shape)\n",
        "  print(res[1], res[1].shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 2 3 0 1 2 3 0 1 2 3 0 1 2 3 0 1 2 3]\n",
            " [4 5 6 7 4 5 6 7 4 5 6 7 4 5 6 7 4 5 6 7]] (2, 20)\n",
            "[[[0 1 2 3]\n",
            "  [1 2 3 0]\n",
            "  [2 3 0 1]\n",
            "  [3 0 1 2]]\n",
            "\n",
            " [[4 5 6 7]\n",
            "  [5 6 7 4]\n",
            "  [6 7 4 5]\n",
            "  [7 4 5 6]]] (2, 4, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Lutp9_FXWt",
        "colab_type": "code",
        "colab": {
          "height": 35
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592033104842,
          "user_tz": 240,
          "elapsed": 379,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "9cd5e64e-8a02-4213-8946-067d0a0766e9"
      },
      "source": [
        "tf.linalg.diag([1.63685679, 1.00188148, 1.25753987, 0.450119644])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'diag_183:0' shape=(4, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgzxqroPkRjC",
        "colab_type": "code",
        "colab": {
          "height": 35
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592033173545,
          "user_tz": 240,
          "elapsed": 418,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "c009ee3a-7e93-4f54-c59a-33963c367f23"
      },
      "source": [
        "tf.diag_part(tf.random.normal((5, 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'DiagPart:0' shape=(5,) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 437
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktSY9yoPkYLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9tSJNGUoKlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#W = np.array([[0, 1, 0, 0, 1], [1, 0, 1,0, 0], [0,1,0,1,0],[0,0,1,0,1], [1,0,1,0,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7waCLegozfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = np.diag([2,2,2,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPBP_apoo0AG",
        "colab_type": "code",
        "colab": {
          "height": 247
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592443293672,
          "user_tz": 240,
          "elapsed": 612,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "5519ffc8-9daa-4f08-9b18-179ef1993f84"
      },
      "source": [
        "# W = np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0,1,0,1], [1,0,1,0]]) # 4 x 4\n",
        "W = np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0,1,0,1], [1,0,1,0]])\n",
        "# W = np.array([[0, 0, 0, 1], [1, 0, 0, 0], [0,1,0,0], [1,0,0,0]])\n",
        "D = np.diag([2,2,2,2])\n",
        "inv_D = np.sqrt(np.diag(np.ones(4)*1/2.0))\n",
        "# inv_D = np.sqrt(np.diag(np.ones(4)))\n",
        "\n",
        "#print(inv_D)\n",
        "#L = np.eye(4) - np.matmul(np.matmul(inv_D, W), inv_D)\n",
        "L = D-W\n",
        "eigval, eigvec = np.linalg.eig(L)\n",
        "print(D-W)\n",
        "print(L,' \\n', eigval)\n",
        "print(eigvec)\n",
        "#print(np.linalg.inv(eigvec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2 -1  0 -1]\n",
            " [-1  2 -1  0]\n",
            " [ 0 -1  2 -1]\n",
            " [-1  0 -1  2]]\n",
            "[[ 2 -1  0 -1]\n",
            " [-1  2 -1  0]\n",
            " [ 0 -1  2 -1]\n",
            " [-1  0 -1  2]]  \n",
            " [-2.22044605e-16  2.00000000e+00  4.00000000e+00  2.00000000e+00]\n",
            "[[ 5.00000000e-01  7.07106781e-01 -5.00000000e-01  2.77555756e-17]\n",
            " [ 5.00000000e-01 -2.02962647e-16  5.00000000e-01 -7.07106781e-01]\n",
            " [ 5.00000000e-01 -7.07106781e-01 -5.00000000e-01  2.86262916e-16]\n",
            " [ 5.00000000e-01  1.02348685e-16  5.00000000e-01  7.07106781e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRiBenunpE0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "np.set_printoptions(precision=4, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYUI0VXs4YL7",
        "colab_type": "code",
        "colab": {
          "height": 85
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592533831334,
          "user_tz": 420,
          "elapsed": 387,
          "user": {
            "displayName": "Ankush Garg",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgKG9HbM1PFZmfJ-_VdzbbuLmDxqTsX3X302DmYgw=s64",
            "userId": "07839021857476253234"
          }
        },
        "outputId": "abe97c47-40c0-4097-fc78-c8afc7c01499"
      },
      "source": [
        "#np.printoptions(precision=3, suppress=True)\n",
        "import numpy as np\n",
        "def DFT_matrix(N):\n",
        "    i, j = np.meshgrid(np.arange(N), np.arange(N))\n",
        "    omega = np.exp( - 2 * np.pi * 1J / N )\n",
        "    W = np.power( omega, i * j ) / np.sqrt(N)\n",
        "    return W\n",
        "\n",
        "mat_dft = DFT_matrix(4)\n",
        "print(mat_dft)\n",
        "# print(np.linalg.inv(mat_dft))\n",
        "# print(np.linalg.eig(mat_dft))\n",
        "# print(np.linalg.inv(mat_dft))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.5+0.j   0.5+0.j   0.5+0.j   0.5+0.j ]\n",
            " [ 0.5+0.j   0. -0.5j -0.5-0.j  -0. +0.5j]\n",
            " [ 0.5+0.j  -0.5-0.j   0.5+0.j  -0.5-0.j ]\n",
            " [ 0.5+0.j  -0. +0.5j -0.5-0.j   0. -0.5j]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA_usJuFpJkM",
        "colab_type": "code",
        "colab": {
          "height": 88
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592443415803,
          "user_tz": 240,
          "elapsed": 495,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "c8a39248-c29b-43e5-ff64-3ef8aad2baba"
      },
      "source": [
        "eigval, eigvec = np.linalg.eig(L)\n",
        "print(np.matmul(mat_dft, L))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.+0.j  0.+0.j  0.+0.j  0.+0.j]\n",
            " [ 1.+0.j  0.-1.j -1.-0.j -0.+1.j]\n",
            " [ 2.+0.j -2.-0.j  2.+0.j -2.-0.j]\n",
            " [ 1.+0.j -0.+1.j -1.-0.j  0.-1.j]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiI-nf2kpQSq",
        "colab_type": "code",
        "colab": {
          "height": 88
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592443417199,
          "user_tz": 240,
          "elapsed": 396,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "0b24944e-e118-40ae-9080-0b79a38188aa"
      },
      "source": [
        "lambda_mat = np.diag(eigval)\n",
        "print(np.matmul(mat_dft, lambda_mat).transpose())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.+0.j -0.+0.j -0.+0.j -0.+0.j]\n",
            " [ 1.+0.j  0.-1.j -1.-0.j -0.+1.j]\n",
            " [ 2.+0.j -2.-0.j  2.+0.j -2.-0.j]\n",
            " [ 1.+0.j -0.+1.j -1.-0.j  0.-1.j]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC6IdL_lpWZr",
        "colab_type": "code",
        "colab": {
          "height": 424
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592463037566,
          "user_tz": 240,
          "elapsed": 393,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "5bed7a9d-f30d-42c9-8909-b3b9bbae75ef"
      },
      "source": [
        "W = np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0,1,0,1], [1,0,1,0]])\n",
        "D = np.diag([2,2,2,2])\n",
        "inv_D = np.sqrt(np.diag(np.ones(4)*1/2.0))\n",
        "#print(inv_D)\n",
        "L = np.eye(4) - np.matmul(np.matmul(inv_D, W), inv_D)\n",
        "#L = D-W\n",
        "eigval, eigvec = np.linalg.eig(L)\n",
        "print(eigvec)\n",
        "print(mat_dft)\n",
        "mat_dft = DFT_matrix(4)\n",
        "print(np.matmul(L, mat_dft))\n",
        "lambda_mat = np.diag(eigval)\n",
        "print(np.matmul(mat_dft, lambda_mat))\n",
        "print(np.linalg.qr(eigvec))\n",
        "# print('****************8')\n",
        "# print(np.matmul(L, eigvec))\n",
        "# print(np.matmul(eigvec, lambda_mat))\n",
        "\n",
        "# print('*****************')\n",
        "# print(np.matmul(eigvec.transpose(), L))\n",
        "# print(np.matmul(eigvec.transpose(), lambda_mat))\n",
        "\n",
        "# print('*******NO TRANPOSE**********')\n",
        "# print(np.matmul(eigvec, L))\n",
        "# print(np.matmul(eigvec, lambda_mat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.5     0.7071 -0.5     0.    ]\n",
            " [ 0.5     0.     -0.5    -0.7071]\n",
            " [-0.5    -0.7071 -0.5    -0.    ]\n",
            " [ 0.5    -0.     -0.5     0.7071]]\n",
            "[[ 0.5+0.j   0.5+0.j   0.5+0.j   0.5+0.j ]\n",
            " [ 0.5+0.j   0. -0.5j -0.5-0.j  -0. +0.5j]\n",
            " [ 0.5+0.j  -0.5-0.j   0.5+0.j  -0.5-0.j ]\n",
            " [ 0.5+0.j  -0. +0.5j -0.5-0.j   0. -0.5j]]\n",
            "[[-0. +0.j   0.5+0.j   1. +0.j   0.5+0.j ]\n",
            " [-0. +0.j   0. -0.5j -1. -0.j  -0. +0.5j]\n",
            " [-0. +0.j  -0.5-0.j   1. +0.j  -0.5-0.j ]\n",
            " [-0. +0.j  -0. +0.5j -1. -0.j   0. -0.5j]]\n",
            "[[ 1. +0.j   0.5+0.j  -0. +0.j   0.5+0.j ]\n",
            " [ 1. +0.j   0. -0.5j  0. +0.j  -0. +0.5j]\n",
            " [ 1. +0.j  -0.5-0.j  -0. -0.j  -0.5-0.j ]\n",
            " [ 1. +0.j  -0. +0.5j  0. +0.j   0. -0.5j]]\n",
            "(array([[-0.5   , -0.7071, -0.5   , -0.    ],\n",
            "       [ 0.5   , -0.    , -0.5   , -0.7071],\n",
            "       [-0.5   ,  0.7071, -0.5   , -0.    ],\n",
            "       [ 0.5   , -0.    , -0.5   ,  0.7071]]), array([[ 1., -0.,  0., -0.],\n",
            "       [ 0., -1.,  0.,  0.],\n",
            "       [ 0.,  0.,  1.,  0.],\n",
            "       [ 0.,  0.,  0.,  1.]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2nJSR3Gtdki",
        "colab_type": "code",
        "colab": {
          "height": 354
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592440885325,
          "user_tz": 240,
          "elapsed": 364,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "4bc4332c-fe47-47e8-ec19-e57dc5a6f2ca"
      },
      "source": [
        "++W = np.array([[0, 1, 0, 0, 1], [1, 0, 1,0, 0], [0,1,0,1,0],[0,0,1,0,1], [1,0,0,1,0]])\n",
        "D = np.diag([2,2,2,2,2])\n",
        "L = D - W\n",
        "inv_D = np.sqrt(np.diag(np.ones(5)*1/2.0))\n",
        "print(inv_D)\n",
        "L = np.eye(5) - np.matmul(np.matmul(inv_D, W), inv_D)\n",
        "eigval, eigvec = np.linalg.eig(L)\n",
        "print(W, L, eigval, eigvec)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.70710678 0.         0.         0.         0.        ]\n",
            " [0.         0.70710678 0.         0.         0.        ]\n",
            " [0.         0.         0.70710678 0.         0.        ]\n",
            " [0.         0.         0.         0.70710678 0.        ]\n",
            " [0.         0.         0.         0.         0.70710678]]\n",
            "[[0 1 0 0 1]\n",
            " [1 0 1 0 0]\n",
            " [0 1 0 1 0]\n",
            " [0 0 1 0 1]\n",
            " [1 0 0 1 0]] [[ 1.  -0.5  0.   0.  -0.5]\n",
            " [-0.5  1.  -0.5  0.   0. ]\n",
            " [ 0.  -0.5  1.  -0.5  0. ]\n",
            " [ 0.   0.  -0.5  1.  -0.5]\n",
            " [-0.5  0.   0.  -0.5  1. ]] [ 1.80901699e+00  6.90983006e-01 -1.61562165e-16  1.80901699e+00\n",
            "  6.90983006e-01] [[-0.63245553  0.63245553 -0.4472136  -0.22487771  0.14475218]\n",
            " [ 0.51166727  0.19543951 -0.4472136  -0.16552528 -0.54080397]\n",
            " [-0.19543951 -0.51166727 -0.4472136   0.49270325 -0.47898741]\n",
            " [-0.19543951 -0.51166727 -0.4472136  -0.63168532  0.24477347]\n",
            " [ 0.51166727  0.19543951 -0.4472136   0.52938507  0.63026573]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mog-9oVXpZtl",
        "colab_type": "code",
        "colab": {
          "height": 470
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592438391474,
          "user_tz": 240,
          "elapsed": 347,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "f04c452c-a454-4c52-9ec4-b55c11f10a5d"
      },
      "source": [
        "W = np.array([[0, 1, 0, 0, 1.2], [1, 0, 1,0, 0], [0,1,0,1,0],[0,0,1,0,1], [1.2,0,0,1,0]])\n",
        "D = np.diag([2.2,2,2,2,2.2])\n",
        "L = D - W\n",
        "eigval, eigvec = np.linalg.eig(L)\n",
        "print(W, D, L, eigval,'\\n', eigvec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.  1.  0.  0.  1.2]\n",
            " [1.  0.  1.  0.  0. ]\n",
            " [0.  1.  0.  1.  0. ]\n",
            " [0.  0.  1.  0.  1. ]\n",
            " [1.2 0.  0.  1.  0. ]] [[2.2 0.  0.  0.  0. ]\n",
            " [0.  2.  0.  0.  0. ]\n",
            " [0.  0.  2.  0.  0. ]\n",
            " [0.  0.  0.  2.  0. ]\n",
            " [0.  0.  0.  0.  2.2]] [[ 2.2 -1.   0.   0.  -1.2]\n",
            " [-1.   2.  -1.   0.   0. ]\n",
            " [ 0.  -1.   2.  -1.   0. ]\n",
            " [ 0.   0.  -1.   2.  -1. ]\n",
            " [-1.2  0.   0.  -1.   2.2]] [-1.33226763e-15  3.92065556e+00  3.61803399e+00  1.38196601e+00\n",
            "  1.47934444e+00] \n",
            " [[-4.47213595e-01 -6.27188637e-01  1.95439508e-01  5.11667274e-01\n",
            "  -3.26549252e-01]\n",
            " [-4.47213595e-01  3.26549252e-01 -5.11667274e-01 -1.95439508e-01\n",
            "  -6.27188637e-01]\n",
            " [-4.47213595e-01 -1.21020360e-15  6.32455532e-01 -6.32455532e-01\n",
            "  -4.28024111e-15]\n",
            " [-4.47213595e-01 -3.26549252e-01 -5.11667274e-01 -1.95439508e-01\n",
            "   6.27188637e-01]\n",
            " [-4.47213595e-01  6.27188637e-01  1.95439508e-01  5.11667274e-01\n",
            "   3.26549252e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhEz-5Vts7lF",
        "colab_type": "code",
        "colab": {
          "height": 460
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592438209179,
          "user_tz": 240,
          "elapsed": 334,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "61f32859-67fa-44e2-f4df-2685c8eebb3d"
      },
      "source": [
        "W = np.array([[0, 0, 0, 0, 1], [1, 0, 0,0, 0], [0,1,0,0,0],[0,0,1,0,0], [0,0,0,1,0]])\n",
        "D = np.diag([2,2,2,2,2])/2\n",
        "L = D - W\n",
        "eigval, eigvec = np.linalg.eig(L)\n",
        "print(W, D, L)\n",
        "print(eigval, eigvec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 1]\n",
            " [1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]] [[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]] [[ 1.  0.  0.  0. -1.]\n",
            " [-1.  1.  0.  0.  0.]\n",
            " [ 0. -1.  1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0. -1.  1.]]\n",
            "[-1.20186557e-16+0.j          6.90983006e-01+0.95105652j\n",
            "  6.90983006e-01-0.95105652j  1.80901699e+00+0.58778525j\n",
            "  1.80901699e+00-0.58778525j] [[ 0.4472136+0.j         -0.4472136+0.j         -0.4472136-0.j\n",
            "  -0.3618034+0.26286556j -0.3618034-0.26286556j]\n",
            " [ 0.4472136+0.j         -0.1381966-0.4253254j  -0.1381966+0.4253254j\n",
            "   0.1381966-0.4253254j   0.1381966+0.4253254j ]\n",
            " [ 0.4472136+0.j          0.3618034-0.26286556j  0.3618034+0.26286556j\n",
            "   0.1381966+0.4253254j   0.1381966-0.4253254j ]\n",
            " [ 0.4472136+0.j          0.3618034+0.26286556j  0.3618034-0.26286556j\n",
            "  -0.3618034-0.26286556j -0.3618034+0.26286556j]\n",
            " [ 0.4472136+0.j         -0.1381966+0.4253254j  -0.1381966-0.4253254j\n",
            "   0.4472136+0.j          0.4472136-0.j        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7UK30tntmas",
        "colab_type": "code",
        "colab": {
          "height": 52
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1594170240010,
          "user_tz": 240,
          "elapsed": 497,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "39238be8-02cd-4433-a5c1-ba95ea24e4f5"
      },
      "source": [
        "H = 5\n",
        "shape = [H, H]\n",
        "_w_adj = tf.linalg.diag(tf.ones(shape[-1]))\n",
        "w_adj = tf.roll(\n",
        "    _w_adj, shift=[-1, 0], axis=[0, 1]) + tf.roll(\n",
        "        _w_adj, shift=[1, 0], axis=[0, 1])\n",
        "mask = w_adj + _w_adj\n",
        "\n",
        "w_diag = tf.reduce_sum(w_adj, axis=-1)\n",
        "\n",
        "inv_D = tf.linalg.diag(tf.sqrt(1/w_diag))\n",
        "print(inv_D)\n",
        "lap = tf.eye(shape[-1]) - tf.linalg.matmul(tf.linalg.matmul(inv_D, w_adj), inv_D)\n",
        "\n",
        "# laplacian complementary\n",
        "eigval, eigvec = tf.linalg.eigh(lap)\n",
        "eigvec_inv = tf.linalg.inv(eigvec)\n",
        "ortho_eigvec = tf.matmul(tf.transpose(eigvec), eigvec)\n",
        "# zip(eigval, eigvec)\n",
        "#eigval = tf.expand_dims(eigval, -1)\n",
        "print(eigval)\n",
        "eigval_c =  tf.reverse(eigval, axis=[0])\n",
        "\n",
        "lap_c = tf.matmul(tf.matmul(eigvec, tf.linalg.diag(eigval_c)), tf.transpose(eigvec))\n",
        "eigval_cc, eigvec_cc = tf.linalg.eigh(lap_c)\n",
        "\n",
        "mask_c = tf.ones(lap_c.shape)  # tf.cast(lap_c, dtype=tf.float32)\n",
        "sess = tf.compat.v1.Session()\n",
        "with sess.as_default():\n",
        "  result = sess.run([w_adj, w_diag, inv_D, mask, lap, eigval, eigvec, eigvec_inv, ortho_eigvec, eigval_c, lap_c, eigval_cc, eigvec_cc, mask_c])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"diag_7:0\", shape=(5, 5), dtype=float32)\n",
            "Tensor(\"SelfAdjointEigV2:0\", shape=(5,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIttFWbfED6W",
        "colab_type": "code",
        "colab": {
          "height": 300
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1594170388170,
          "user_tz": 240,
          "elapsed": 393,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "a77cddfa-3704-4439-cb25-aae456fe24c8"
      },
      "source": [
        "names = ['w_adj', 'w_diag', 'inv_D', 'mask', 'lap', 'eigval', 'eigvec', \n",
        "         'eigvec_inv', 'ortho_eigvec', 'eigval_c', 'lap_c', 'eigval_cc',\n",
        "         'eigvec_cc', 'mask_c']\n",
        "res_dict = {n:m for n,m in zip(names, result)}\n",
        "# for i, v in enumerate(result):\n",
        "#   if i>5:\n",
        "#     print(i, v)\n",
        "#     print('\\n')\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "for n in ['lap', 'lap_c', 'eigval', 'eigval_c']:\n",
        "  print(n)\n",
        "  #print('Lap-chain')\n",
        "  print(res_dict[n])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lap\n",
            "[[ 1.  -0.5  0.   0.  -0.5]\n",
            " [-0.5  1.  -0.5  0.   0. ]\n",
            " [ 0.  -0.5  1.  -0.5  0. ]\n",
            " [ 0.   0.  -0.5  1.  -0.5]\n",
            " [-0.5  0.   0.  -0.5  1. ]]\n",
            "lap_c\n",
            "[[ 0.9146  0.2236  0.2236  0.2236  0.2236]\n",
            " [ 0.2236  1.2236  0.6281 -0.1809 -0.0854]\n",
            " [ 0.2236  0.6281  0.8191  0.3191 -0.1809]\n",
            " [ 0.2236 -0.1809  0.3191  0.8191  0.6281]\n",
            " [ 0.2236 -0.0854 -0.1809  0.6281  1.2236]]\n",
            "eigval\n",
            "[0.    0.691 0.691 1.809 1.809]\n",
            "eigval_c\n",
            "[1.809 1.809 0.691 0.691 0.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnQ9ENE0HlKJ",
        "colab_type": "code",
        "colab": {
          "height": 447
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595278967419,
          "user_tz": 240,
          "elapsed": 610,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "e7c6348a-c542-49e7-fbb2-1652f766aad2"
      },
      "source": [
        "# for input weight: scrbd topology\n",
        "sessibd = tf.compat.v1.Session()  \n",
        "\n",
        "def get_complementary_topology_SVD(lap, dtype):\n",
        "  # take the svd\n",
        "  sigma, U, V = tf.linalg.svd(lap)\n",
        "  print(U, sigma, V)\n",
        "  # reverse the sigma\n",
        "  # sigma = tf.expand_dims(sigma,-1)\n",
        "  sigma_c = tf.reverse(sigma, axis=[0])#\n",
        "  print('resverse: ', sigma_c)\n",
        "  # # get the complementary laplacian\n",
        "  # lap_c = tf.matmul(U, )\n",
        "  lap_c = tf.matmul(U, tf.matmul(tf.linalg.diag(sigma_c), V, adjoint_b=True))\n",
        "  mask_c = tf.ones(lap_c.shape)\n",
        "  # mask_c = tf.cast(mask_c, dtype=dtype)\n",
        "  # lap_c = tf.cast(lap_c, dtype=dtype)\n",
        "  return lap_c, mask_c\n",
        "\n",
        "with sessibd.as_default(): # initialize the reservoir weights\n",
        "      shape = (6,6)\n",
        "      # shape0, shape1 = shape[-2], shape[-1]\n",
        "      dim0, dim1 = shape[-2], shape[-1]\n",
        "      if dim0 <= dim1:\n",
        "        shape0, shape1 = dim0, dim1\n",
        "        do_transpose = False\n",
        "      else:\n",
        "        shape0, shape1 = dim1, dim0\n",
        "        do_transpose = True\n",
        "      # assuming shape0 < shape1:\n",
        "      repeat = math.ceil(shape1/shape0) - 1\n",
        "      w_scr = tf.eye(shape0)\n",
        "      for i in range(repeat):\n",
        "        if i == repeat - 1: # truncate\n",
        "          w_diag = tf.eye(shape0)\n",
        "          w_scr = tf.concat([w_scr, w_diag[:, :(shape1-shape0)]], axis=1)\n",
        "        else:\n",
        "          w_scr = tf.concat([w_scr, tf.eye(shape0) ], axis=1)\n",
        "      D_mat = w_scr\n",
        "      adj_mat = tf.roll(w_scr, shift=[-1, 0], axis=[0, 1]) + tf.roll(w_scr, shift=[1, 0], axis=[0, 1])\n",
        "      w_scr = adj_mat + D_mat\n",
        "      # the transpose condition\n",
        "      if do_transpose:\n",
        "        w_scr = tf.transpose(w_scr, perm=[1, 0])\n",
        "\n",
        "      mask = w_scr # tf.cast(w_scr, dtype=dtype)\n",
        "      # should have v and mask\n",
        "      D_mat = D_mat*tf.reduce_sum(adj_mat, axis=-1)[0]  # scalar\n",
        "      v = D_mat - adj_mat\n",
        "\n",
        "      # SVD code check\n",
        "      lap_c, mask_c = get_complementary_topology_SVD(v, 'dtype')\n",
        "\n",
        "      print_op = tf.print(\"tensors:\", mask,v, lap_c, mask_c,\n",
        "                          output_stream=sys.stdout)  \n",
        "      with tf.control_dependencies([print_op]):  \n",
        "        tripled_tensor = w_scr * 3  \n",
        "      sessibd.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Svd_1:1\", shape=(6, 6), dtype=float32) Tensor(\"Svd_1:0\", shape=(6,), dtype=float32) Tensor(\"Svd_1:2\", shape=(6, 6), dtype=float32)\n",
            "resverse:  Tensor(\"ReverseV2:0\", shape=(6,), dtype=float32)\n",
            "tensors: [[1 1 0 0 0 1]\n",
            " [1 1 1 0 0 0]\n",
            " [0 1 1 1 0 0]\n",
            " [0 0 1 1 1 0]\n",
            " [0 0 0 1 1 1]\n",
            " [1 0 0 0 1 1]] [[2 -1 0 0 0 -1]\n",
            " [-1 2 -1 0 0 0]\n",
            " [0 -1 2 -1 0 0]\n",
            " [0 0 -1 2 -1 0]\n",
            " [0 0 0 -1 2 -1]\n",
            " [-1 0 0 0 -1 2]] [[2.00000119 1.00000036 2.61051468e-07 -5.62475918e-07 -2.91244419e-07 1.00000024]\n",
            " [1.00000048 2.00000072 1.00000036 -2.42577386e-07 -2.09764451e-07 -4.79094027e-08]\n",
            " [3.69323089e-07 1.00000036 2.00000072 1.00000048 -4.37245376e-07 1.41842165e-07]\n",
            " [-3.83662e-07 -1.72035115e-07 1.00000036 2.00000143 1.00000012 4.45081518e-08]\n",
            " [-2.53515111e-07 -1.01492823e-07 -5.07787661e-07 1.00000036 2.00000072 1.00000083]\n",
            " [1.00000024 -1.45243405e-07 -1.34305751e-07 -1.23368096e-07 1.00000072 2.00000095]] [[1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnwTyg5Op65E",
        "colab_type": "code",
        "colab": {
          "height": 35
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1592949152255,
          "user_tz": 240,
          "elapsed": 463,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "5652d148-d2f4-452e-b1e8-65530896cce0"
      },
      "source": [
        "wt = 'spec_lap_chain'\n",
        "if 'spec' in wt:\n",
        "  print(wt[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ldN_lJkI9Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKeZ-atk6tee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUoG9_4K8bXc",
        "colab_type": "code",
        "colab": {
          "height": 279
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275388991,
          "user_tz": 240,
          "elapsed": 436,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "7fb9634e-9507-4ebb-9266-4b304c4a1449"
      },
      "source": [
        "R = 2048\n",
        "def get_closest_int(R):\n",
        "  # R = f1 x f2, where f1 f2 are the closest\n",
        "  f1 = np.ceil(np.sqrt(R))\n",
        "  while(True):\n",
        "    if f1==R:\n",
        "      f2 = 1\n",
        "      break\n",
        "    elif R%f1==0:\n",
        "      f2 = R/f1\n",
        "      break\n",
        "    else:\n",
        "      f1 += 1\n",
        "  return [int(f1), int(f2)]\n",
        "grid_dim = get_closest_int(R)\n",
        "print(grid_dim)\n",
        "G = nx.grid_graph(grid_dim, periodic=True)\n",
        "A = nx.to_numpy_matrix(G)\n",
        "print(A, np.sum(A, axis=-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[64, 32]\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 1. 0. 1.]\n",
            " [0. 0. 0. ... 0. 1. 0.]] [[4.]\n",
            " [4.]\n",
            " [4.]\n",
            " ...\n",
            " [4.]\n",
            " [4.]\n",
            " [4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjGcIhaP42On",
        "colab_type": "code",
        "colab": {
          "height": 204
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275390024,
          "user_tz": 240,
          "elapsed": 400,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "788e3e2f-f792-48a3-d0cb-b6dd53542d45"
      },
      "source": [
        "# Laplacian Grid topology for reservoir\n",
        "sess2 = tf.compat.v1.Session()  \n",
        "\n",
        "def get_lap_grid(R):\n",
        "    grid_dim = get_closest_int(R)\n",
        "    print(grid_dim)\n",
        "    G = nx.grid_graph(grid_dim, periodic=True)\n",
        "    A = nx.to_numpy_matrix(G)\n",
        "    A = tf.convert_to_tensor(A)\n",
        "    D = tf.reduce_sum(A, axis=-1)\n",
        "    L = tf.linalg.diag(D)-A\n",
        "    if R %2==0: # even\n",
        "      mask = tf.linalg.diag(tf.ones(A.shape[-1], dtype=A.dtype)) + A\n",
        "    else: # odd\n",
        "      mask = A\n",
        "    return L, mask\n",
        "\n",
        "with sess2.as_default(): # initialize the reservoir weights\n",
        "    shape = (6, 6)\n",
        "    R = shape[-1]\n",
        "    L, mask = get_lap_grid(R)\n",
        "    print('L:', L.shape)\n",
        "    # L = tf.convert_to_tensor(L) # dtype=dtype\n",
        "    # take the svd\n",
        "    eigval, eigvec = tf.linalg.eigh(L)\n",
        "    print(eigval, eigvec)\n",
        "    # print_op = tf.print(\"tensors:\", mask, L, eigval, eigvec, \n",
        "    #                     output_stream=sys.stdout) \n",
        "    print_op = tf.print(\"Lap-grid:\\n\", L,\n",
        "                        output_stream=sys.stdout)  \n",
        "    with tf.control_dependencies([print_op]):  \n",
        "      tripled_tensor = w_scr * 3\n",
        "    sess2.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 2]\n",
            "L: (6, 6)\n",
            "Tensor(\"SelfAdjointEigV2:0\", shape=(6,), dtype=float64) Tensor(\"SelfAdjointEigV2:1\", shape=(6, 6), dtype=float64)\n",
            "Lap-grid:\n",
            " [[3 -1 -1 -1 0 0]\n",
            " [-1 3 -1 0 -1 0]\n",
            " [-1 -1 3 0 0 -1]\n",
            " [-1 0 0 3 -1 -1]\n",
            " [0 -1 0 -1 3 -1]\n",
            " [0 0 -1 -1 -1 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8wJgqtn9zyB",
        "colab_type": "code",
        "colab": {
          "height": 485
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275391883,
          "user_tz": 240,
          "elapsed": 386,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "d7660cf2-8886-4eb1-92e2-c3d2b6e815bd"
      },
      "source": [
        "# Laplacian Grid topology for reservoir\n",
        "sess2 = tf.compat.v1.Session()  \n",
        "\n",
        "with sess2.as_default(): # initialize the reservoir weights\n",
        "    shape = (6,6)\n",
        "    # shape0, shape1 = shape[-2], shape[-1]\n",
        "    dim0, dim1 = shape[-2], shape[-1]\n",
        "    if dim0 <= dim1:\n",
        "      shape0, shape1 = dim0, dim1\n",
        "      do_transpose = False\n",
        "    else:\n",
        "      shape0, shape1 = dim1, dim0\n",
        "      do_transpose = True\n",
        "    # assuming shape0 < shape1:\n",
        "    repeat = math.ceil(shape1/shape0) - 1\n",
        "    L, mask = get_lap_grid(R=shape0)\n",
        "    for i in range(repeat):\n",
        "      tempL, tempM = get_lap_grid(R=shape0)\n",
        "      if i == repeat - 1: # truncate\n",
        "        L = tf.concat([L, tempL[:, :(shape1-shape0)]], axis=1)\n",
        "        mask = tf.concat([mask, tempM[:, :(shape1-shape0)]], axis=1)\n",
        "      else:\n",
        "        L = tf.concat([L, tempL], axis=1)\n",
        "        mask = tf.concat([mask, tempM], axis=1)\n",
        "    # the transpose condition\n",
        "    if do_transpose:\n",
        "      L = tf.transpose(L, perm=[1, 0])\n",
        "      mask = tf.transpose(mask, perm=[1, 0])\n",
        "    print('L:', L.shape, mask.shape)\n",
        "    # L = tf.convert_to_tensor(L) # dtype=dtype\n",
        "    # take the svd\n",
        "    sigma, U, V = tf.linalg.svd(L)\n",
        "    print(U, sigma, V)\n",
        "    print_op = tf.print(\"tensors:\", mask, L, sigma, U, V, \n",
        "                        output_stream=sys.stdout)  \n",
        "    with tf.control_dependencies([print_op]):  \n",
        "      tripled_tensor = L * 3\n",
        "    sess2.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 2]\n",
            "L: (6, 6) (6, 6)\n",
            "Tensor(\"Svd:1\", shape=(6, 6), dtype=float64) Tensor(\"Svd:0\", shape=(6,), dtype=float64) Tensor(\"Svd:2\", shape=(6, 6), dtype=float64)\n",
            "tensors: [[1 1 1 1 0 0]\n",
            " [1 1 1 0 1 0]\n",
            " [1 1 1 0 0 1]\n",
            " [1 0 0 1 1 1]\n",
            " [0 1 0 1 1 1]\n",
            " [0 0 1 1 1 1]] [[3 -1 -1 -1 0 0]\n",
            " [-1 3 -1 0 -1 0]\n",
            " [-1 -1 3 0 0 -1]\n",
            " [-1 0 0 3 -1 -1]\n",
            " [0 -1 0 -1 3 -1]\n",
            " [0 0 -1 -1 -1 3]] [5.0000000000000062 5.0000000000000009 3.0000000000000018 3.0000000000000009 2.0000000000000018 6.5852386286146089e-17] [[0.32928587099560352 -0.47424060190582584 -0.21526894104448838 0.53571691811526545 -0.40824829046386291 0.40824829046386329]\n",
            " [-0.57534734425427 -0.048049628436564969 -0.35630998980268397 -0.45428683064793413 -0.408248290463863 0.40824829046386357]\n",
            " [0.24606147325866684 0.522290230342391 0.57157893084717226 -0.081430087467331588 -0.40824829046386329 0.40824829046386324]\n",
            " [-0.32928587099560352 0.47424060190582634 -0.21526894104448793 0.53571691811526512 0.408248290463863 0.40824829046386335]\n",
            " [0.57534734425427037 0.048049628436564518 -0.35630998980268364 -0.454286830647934 0.40824829046386329 0.40824829046386352]\n",
            " [-0.24606147325866681 -0.52229023034239075 0.57157893084717237 -0.081430087467330992 0.40824829046386268 0.40824829046386346]] [[0.32928587099560352 -0.4742406019058259 -0.21526894104448832 0.53571691811526567 -0.40824829046386291 0.40824829046386313]\n",
            " [-0.57534734425427 -0.048049628436565024 -0.356309989802684 -0.45428683064793418 -0.408248290463863 0.40824829046386352]\n",
            " [0.24606147325866687 0.52229023034239108 0.571578930847172 -0.081430087467331561 -0.40824829046386346 0.40824829046386318]\n",
            " [-0.32928587099560347 0.47424060190582634 -0.21526894104448802 0.53571691811526534 0.40824829046386307 0.40824829046386329]\n",
            " [0.57534734425427037 0.048049628436564538 -0.35630998980268364 -0.45428683064793413 0.40824829046386352 0.40824829046386346]\n",
            " [-0.24606147325866687 -0.52229023034239086 0.57157893084717248 -0.081430087467331019 0.40824829046386291 0.40824829046386335]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15HB84_waFgq",
        "colab_type": "code",
        "colab": {
          "height": 204
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595275404336,
          "user_tz": 240,
          "elapsed": 490,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "5794c7c7-6e4e-44cf-fea2-a092297cf553"
      },
      "source": [
        "# Laplacian Small world topology\n",
        "sess2 = tf.compat.v1.Session()  \n",
        "\n",
        "def get_lap(R, topo):\n",
        "    if topo=='chain':\n",
        "      G = nx.grid_graph([R], periodic=True)\n",
        "    elif topo=='grid':\n",
        "      grid_dim = get_closest_int(R)\n",
        "      print(grid_dim)\n",
        "      G = nx.grid_graph(grid_dim, periodic=True)\n",
        "    elif topo=='sw': # small world\n",
        "      mean_degree = int(np.ceil(0.1*R))+1 # 10% of Total nodes\n",
        "      print('R, k ', R, mean_degree)\n",
        "      rewiring_prob = 0.5 # randomly choose 1/2 of the neiboring nodes from other nodes\n",
        "      G = nx.connected_watts_strogatz_graph(R, mean_degree, rewiring_prob, seed=None)\n",
        "    else:\n",
        "      print('Laplacian topology not defined')\n",
        "    A = nx.to_numpy_matrix(G)\n",
        "    A = tf.convert_to_tensor(A)\n",
        "    D = tf.reduce_sum(A, axis=-1)\n",
        "    L = tf.linalg.diag(D)-A\n",
        "    if R %2==0: # even\n",
        "      mask = tf.linalg.diag(tf.ones(A.shape[-1], dtype=A.dtype)) + A\n",
        "    else: # odd\n",
        "      mask = A\n",
        "    return L, mask\n",
        "\n",
        "with sess2.as_default(): # initialize the reservoir weights\n",
        "    shape = (6, 6)\n",
        "    R = shape[-1]\n",
        "    L, mask = get_lap(R, 'sw')\n",
        "    print('L:', L.shape)\n",
        "    # L = tf.convert_to_tensor(L) # dtype=dtype\n",
        "    # take the svd\n",
        "    eigval, eigvec = tf.linalg.eigh(L)\n",
        "    print(eigval, eigvec)\n",
        "    # print_op = tf.print(\"tensors:\", mask, L, eigval, eigvec, \n",
        "    #                     output_stream=sys.stdout)  \n",
        "    print_op = tf.print(\"Lap-SmallWorld:\\n\", L, \n",
        "                        output_stream=sys.stdout)  \n",
        "    with tf.control_dependencies([print_op]):  \n",
        "      tripled_tensor = L * 3\n",
        "    sess2.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R, k  6 2\n",
            "L: (6, 6)\n",
            "Tensor(\"SelfAdjointEigV2_1:0\", shape=(6,), dtype=float64) Tensor(\"SelfAdjointEigV2_1:1\", shape=(6, 6), dtype=float64)\n",
            "Lap-SmallWorld:\n",
            " [[2 -1 0 0 0 -1]\n",
            " [-1 2 0 0 0 -1]\n",
            " [0 0 2 0 -1 -1]\n",
            " [0 0 0 1 -1 0]\n",
            " [0 0 -1 -1 2 0]\n",
            " [-1 -1 -1 0 0 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeWS9gFBJrRd",
        "colab_type": "code",
        "colab": {
          "height": 279
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1595142270340,
          "user_tz": 240,
          "elapsed": 407,
          "user": {
            "displayName": "Harsh Shrivastava",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gis1C2sA-R_sxgKx2t6iAnjFmlel60dObgDgV7VHA=s64",
            "userId": "00092728178824740487"
          }
        },
        "outputId": "d0cbb55d-5541-420c-9988-8b68a86935f8"
      },
      "source": [
        "with sess2.as_default(): # initialize the reservoir weights\n",
        "    shape = (6, 6)\n",
        "    R = shape[-1]\n",
        "    L, mask = get_lap(R, 'chain')\n",
        "    print('L:', L.shape)\n",
        "    # L = tf.convert_to_tensor(L) # dtype=dtype\n",
        "    # take the svd\n",
        "    eigval, eigvec = tf.linalg.eigh(L)\n",
        "    print(eigval, eigvec)\n",
        "    # print_op = tf.print(\"tensors:\", mask, L, eigval, eigvec, \n",
        "    #                     output_stream=sys.stdout)  \n",
        "    print_op = tf.print(\"Lap-Chain:\\n\", L, mask,\n",
        "                        output_stream=sys.stdout)  \n",
        "    with tf.control_dependencies([print_op]):  \n",
        "      tripled_tensor = L * 3\n",
        "    sess2.run(tripled_tensor) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L: (6, 6)\n",
            "Tensor(\"SelfAdjointEigV2_4:0\", shape=(6,), dtype=float64) Tensor(\"SelfAdjointEigV2_4:1\", shape=(6, 6), dtype=float64)\n",
            "Lap-Chain:\n",
            " [[2 -1 0 0 0 -1]\n",
            " [-1 2 -1 0 0 0]\n",
            " [0 -1 2 -1 0 0]\n",
            " [0 0 -1 2 -1 0]\n",
            " [0 0 0 -1 2 -1]\n",
            " [-1 0 0 0 -1 2]] [[1 1 0 0 0 1]\n",
            " [1 1 1 0 0 0]\n",
            " [0 1 1 1 0 0]\n",
            " [0 0 1 1 1 0]\n",
            " [0 0 0 1 1 1]\n",
            " [1 0 0 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke6Govdtz8mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}